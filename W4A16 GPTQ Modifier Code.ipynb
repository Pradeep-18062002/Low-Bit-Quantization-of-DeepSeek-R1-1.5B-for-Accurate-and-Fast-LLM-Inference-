{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "884eb0767d7e40a3bbf66a5999e69838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a7dd1868c634c949cadd2140403a5fa",
              "IPY_MODEL_674db16d35e84350a250b4ab05764df8",
              "IPY_MODEL_ca9b87d94c8946ea9e6676dec97cea6a"
            ],
            "layout": "IPY_MODEL_0bbe2adf7c764b94a18faf1094215d8b"
          }
        },
        "8a7dd1868c634c949cadd2140403a5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfff6d5f0a854de1aab25af2f12a53d1",
            "placeholder": "​",
            "style": "IPY_MODEL_e4bcb74f13d24f68961b1dda71c5eebf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "674db16d35e84350a250b4ab05764df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c8754ae8a74f3da6c39e8de37cb047",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0152508b81c14c68843d0fa1560e7fa7",
            "value": 3071
          }
        },
        "ca9b87d94c8946ea9e6676dec97cea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a65067ba1f848f79c73ab5856e0ffb8",
            "placeholder": "​",
            "style": "IPY_MODEL_d81015cd8c9f403f9499f43d2ba67a3d",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 362kB/s]"
          }
        },
        "0bbe2adf7c764b94a18faf1094215d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfff6d5f0a854de1aab25af2f12a53d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4bcb74f13d24f68961b1dda71c5eebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c8754ae8a74f3da6c39e8de37cb047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0152508b81c14c68843d0fa1560e7fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a65067ba1f848f79c73ab5856e0ffb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81015cd8c9f403f9499f43d2ba67a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0a90cf8f254a1da58f55f97b7e089b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77741ee5842b434a8a7a384dfd316a7d",
              "IPY_MODEL_287162785adb45d59cc5ba79f44035db",
              "IPY_MODEL_436a82e2aafa43bebd7c42e8cb59917c"
            ],
            "layout": "IPY_MODEL_90a513bc4d3b444e811bbd7fd9ad4b88"
          }
        },
        "77741ee5842b434a8a7a384dfd316a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8644f0db9f3a493296e6da8ca9520342",
            "placeholder": "​",
            "style": "IPY_MODEL_b23871e0084247eabeb130b43dcbe9dd",
            "value": "tokenizer.json: 100%"
          }
        },
        "287162785adb45d59cc5ba79f44035db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c34d1938c94b13b6436dc1e359327b",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_791874deda7a44cda61976436e294112",
            "value": 7031660
          }
        },
        "436a82e2aafa43bebd7c42e8cb59917c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a8dcd397f24aec88205ce248598320",
            "placeholder": "​",
            "style": "IPY_MODEL_c3724bcae09a4551b8d82277b3fec3ff",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "90a513bc4d3b444e811bbd7fd9ad4b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8644f0db9f3a493296e6da8ca9520342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23871e0084247eabeb130b43dcbe9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c34d1938c94b13b6436dc1e359327b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791874deda7a44cda61976436e294112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55a8dcd397f24aec88205ce248598320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3724bcae09a4551b8d82277b3fec3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feef90c62eb84360afe521a5f569f712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7097e13efaa4cdaba8599980714350d",
              "IPY_MODEL_cf45a13f650a4468a89b150f7cbfd06e",
              "IPY_MODEL_e2e250e627744f6a85475697768303bd"
            ],
            "layout": "IPY_MODEL_96ed6f23e9a04719be2b867c662481ac"
          }
        },
        "a7097e13efaa4cdaba8599980714350d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f592330855624f75aa333674299ac27b",
            "placeholder": "​",
            "style": "IPY_MODEL_4be989b365844f77a9b325bbde755544",
            "value": "config.json: 100%"
          }
        },
        "cf45a13f650a4468a89b150f7cbfd06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9a83e470cf4b92b58aca925157f61e",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66f94418aa464eb884774e38eda2847c",
            "value": 679
          }
        },
        "e2e250e627744f6a85475697768303bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee358fe9ddcf449eb6ee3fa289d6daac",
            "placeholder": "​",
            "style": "IPY_MODEL_60c0f222ae8745a8ad5fe478139ec3f0",
            "value": " 679/679 [00:00&lt;00:00, 89.9kB/s]"
          }
        },
        "96ed6f23e9a04719be2b867c662481ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f592330855624f75aa333674299ac27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be989b365844f77a9b325bbde755544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a9a83e470cf4b92b58aca925157f61e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f94418aa464eb884774e38eda2847c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee358fe9ddcf449eb6ee3fa289d6daac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c0f222ae8745a8ad5fe478139ec3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dad480860644e39be169310f7e6c139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbd36b8c843644db9f99ef49bb327c71",
              "IPY_MODEL_ab07c1379a634d0eb65afb426362f5cd",
              "IPY_MODEL_2f48fa7ea7c54b5b8d11948f4250f67b"
            ],
            "layout": "IPY_MODEL_b7d068f9175a4911907331ca6f68ccac"
          }
        },
        "fbd36b8c843644db9f99ef49bb327c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758d7ccf208f44598bcf21e8753e3a08",
            "placeholder": "​",
            "style": "IPY_MODEL_0dab3a798ee94167b380b107b35d68b3",
            "value": "model.safetensors: 100%"
          }
        },
        "ab07c1379a634d0eb65afb426362f5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc9936d298a943f180ce21c83252cf3a",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_101d0f4e64524729afbe2327f09ae195",
            "value": 3554214621
          }
        },
        "2f48fa7ea7c54b5b8d11948f4250f67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ecb4958ff78453698b951e32bb45a3b",
            "placeholder": "​",
            "style": "IPY_MODEL_964cdbe93f6d41048c943ec51c36269a",
            "value": " 3.55G/3.55G [00:14&lt;00:00, 253MB/s]"
          }
        },
        "b7d068f9175a4911907331ca6f68ccac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758d7ccf208f44598bcf21e8753e3a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dab3a798ee94167b380b107b35d68b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc9936d298a943f180ce21c83252cf3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "101d0f4e64524729afbe2327f09ae195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ecb4958ff78453698b951e32bb45a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964cdbe93f6d41048c943ec51c36269a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6ae142ed3ee46a9af9f6e9537e8c00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_983c29f5322a4d32b4a74af37c5b4050",
              "IPY_MODEL_28e266fd54c443099abfbdc6052a3dac",
              "IPY_MODEL_14c8c8dd3e0b47c1bc1c58e6c0781c60"
            ],
            "layout": "IPY_MODEL_51f8859ce3404f95ace404a98ae0a003"
          }
        },
        "983c29f5322a4d32b4a74af37c5b4050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af6de3ff4204d42ae98ed82a73d1995",
            "placeholder": "​",
            "style": "IPY_MODEL_52d570676df44180bddfae77c747206e",
            "value": "generation_config.json: 100%"
          }
        },
        "28e266fd54c443099abfbdc6052a3dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504d9c84b9ce42bbbc13dfa17107ea28",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11141c9ba5e24266aa32ecfffcd97a09",
            "value": 181
          }
        },
        "14c8c8dd3e0b47c1bc1c58e6c0781c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc21e43deb61483cbf38ee21c963f02a",
            "placeholder": "​",
            "style": "IPY_MODEL_a997cd221cae414aa8c02113d1130424",
            "value": " 181/181 [00:00&lt;00:00, 23.5kB/s]"
          }
        },
        "51f8859ce3404f95ace404a98ae0a003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af6de3ff4204d42ae98ed82a73d1995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d570676df44180bddfae77c747206e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "504d9c84b9ce42bbbc13dfa17107ea28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11141c9ba5e24266aa32ecfffcd97a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc21e43deb61483cbf38ee21c963f02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a997cd221cae414aa8c02113d1130424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5d68550764249f09145dc452caf2632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09e8dd62ce554d4ca16411b3ad2c54d8",
              "IPY_MODEL_7f336264099d4a039938d193f2c771b7",
              "IPY_MODEL_30978dbb7515474cafb630c8a54c9fad"
            ],
            "layout": "IPY_MODEL_5b17ba2ffe5440dfa2feaa7f2d519eb5"
          }
        },
        "09e8dd62ce554d4ca16411b3ad2c54d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2818ecbe415d46c7a4a301c5ac22b707",
            "placeholder": "​",
            "style": "IPY_MODEL_b335361466f7471d956f9acef1c4d28e",
            "value": "README.md: 100%"
          }
        },
        "7f336264099d4a039938d193f2c771b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd7358bb39e74503ae8ee2605c5976db",
            "max": 832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed807598acec40a08e872d177e3eedd7",
            "value": 832
          }
        },
        "30978dbb7515474cafb630c8a54c9fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be32b36831f8427d8cb86c8f6e660a3a",
            "placeholder": "​",
            "style": "IPY_MODEL_e3640ee45dc44265a53b8897f905a7ab",
            "value": " 832/832 [00:00&lt;00:00, 103kB/s]"
          }
        },
        "5b17ba2ffe5440dfa2feaa7f2d519eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2818ecbe415d46c7a4a301c5ac22b707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b335361466f7471d956f9acef1c4d28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7358bb39e74503ae8ee2605c5976db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed807598acec40a08e872d177e3eedd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be32b36831f8427d8cb86c8f6e660a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3640ee45dc44265a53b8897f905a7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eea1fa0ec28476ca50a9078465357cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbbc2a72e2864de782d8a33ad87f7c1d",
              "IPY_MODEL_2f67e3159288469eb5ae57f3f731ec9b",
              "IPY_MODEL_9b831923177449148c6012b0aaad10dd"
            ],
            "layout": "IPY_MODEL_d56cea9955034b01a6d71b3510c16b37"
          }
        },
        "cbbc2a72e2864de782d8a33ad87f7c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08aa02d19f54bd7bc6a040fb2c3cffc",
            "placeholder": "​",
            "style": "IPY_MODEL_bfcaa9206b3f463586dcb7f30372ae20",
            "value": "calibration.json.gz: 100%"
          }
        },
        "2f67e3159288469eb5ae57f3f731ec9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f85afb92bc418bae1452ebc6fa2833",
            "max": 4575521,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8019d71152b24f12b4512d75039028b8",
            "value": 4575521
          }
        },
        "9b831923177449148c6012b0aaad10dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13d5a2ae6c34910bb5c37cf09765122",
            "placeholder": "​",
            "style": "IPY_MODEL_d8863d0df3c14c65afa41e93a9a02387",
            "value": " 4.58M/4.58M [00:00&lt;00:00, 18.0MB/s]"
          }
        },
        "d56cea9955034b01a6d71b3510c16b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08aa02d19f54bd7bc6a040fb2c3cffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfcaa9206b3f463586dcb7f30372ae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f85afb92bc418bae1452ebc6fa2833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8019d71152b24f12b4512d75039028b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e13d5a2ae6c34910bb5c37cf09765122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8863d0df3c14c65afa41e93a9a02387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a90192439eb5425790daedb20d0a5a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b417d518a7b419c9aa89fa99bf1e53d",
              "IPY_MODEL_50ed6187a2e74781815876a9c9922681",
              "IPY_MODEL_975ffa398e084b75b481baa9fad39f38"
            ],
            "layout": "IPY_MODEL_a6fbc8df47e849e7aee851e4f70bab9f"
          }
        },
        "9b417d518a7b419c9aa89fa99bf1e53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dedd90e90e146b6bc87aee0a22d502a",
            "placeholder": "​",
            "style": "IPY_MODEL_81adf07e79c349818e6f9fa72de9f96a",
            "value": "Generating train split: 100%"
          }
        },
        "50ed6187a2e74781815876a9c9922681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222035718bef4eda85a9e7259207deac",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e172991e2004e04b12c88f1f7c79e80",
            "value": 10000
          }
        },
        "975ffa398e084b75b481baa9fad39f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ac48f6fbb64601960e48e81da35a91",
            "placeholder": "​",
            "style": "IPY_MODEL_b0dd6757a18845539570a909cca27c96",
            "value": " 10000/10000 [00:00&lt;00:00, 39256.02 examples/s]"
          }
        },
        "a6fbc8df47e849e7aee851e4f70bab9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dedd90e90e146b6bc87aee0a22d502a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81adf07e79c349818e6f9fa72de9f96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "222035718bef4eda85a9e7259207deac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e172991e2004e04b12c88f1f7c79e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ac48f6fbb64601960e48e81da35a91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0dd6757a18845539570a909cca27c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1ea06311fb46df8feb8488a5fff5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bec217e3d2e441bc8786ad74956dfb2d",
              "IPY_MODEL_92c2ef1f50c24028a1bce5de08ef600a",
              "IPY_MODEL_32f43b06c01049b7b0be41b70e9323fe"
            ],
            "layout": "IPY_MODEL_2764d69624f049e88674c048ba3186a3"
          }
        },
        "bec217e3d2e441bc8786ad74956dfb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d55ad139c9436295398d95fcc616ea",
            "placeholder": "​",
            "style": "IPY_MODEL_fbcd38ab16fa4f2cb3bbad9db3ae6b67",
            "value": "Map: 100%"
          }
        },
        "92c2ef1f50c24028a1bce5de08ef600a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef28e43943394c8d94c80ed78a242e67",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edb5c27e5de2449a8e008b314356965e",
            "value": 10000
          }
        },
        "32f43b06c01049b7b0be41b70e9323fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f4e872e33d4fc29742682787761791",
            "placeholder": "​",
            "style": "IPY_MODEL_f44a3ab46e164c99b03f1352514dbf93",
            "value": " 10000/10000 [00:01&lt;00:00, 5962.68 examples/s]"
          }
        },
        "2764d69624f049e88674c048ba3186a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d55ad139c9436295398d95fcc616ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbcd38ab16fa4f2cb3bbad9db3ae6b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef28e43943394c8d94c80ed78a242e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb5c27e5de2449a8e008b314356965e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2f4e872e33d4fc29742682787761791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44a3ab46e164c99b03f1352514dbf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3090e0463c64f558aff8b11aa9f88c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d5f7282940343b7b5f0cd1c794fd5cd",
              "IPY_MODEL_6fb0ab3d24f146008cda9ebfd6843f57",
              "IPY_MODEL_dfd19c6f6b334c139e6b70c956c09509"
            ],
            "layout": "IPY_MODEL_f6609149507f46afa81c577285157f3c"
          }
        },
        "1d5f7282940343b7b5f0cd1c794fd5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a395be316c2a427fb06095ff67f37b41",
            "placeholder": "​",
            "style": "IPY_MODEL_0036d81ff68f4db1992493e9da22e90e",
            "value": "Tokenizing: 100%"
          }
        },
        "6fb0ab3d24f146008cda9ebfd6843f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7617b1129e534a5d9374eac67b71eb0f",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a2310f28d324181ad0ab4ab9561c32b",
            "value": 10000
          }
        },
        "dfd19c6f6b334c139e6b70c956c09509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8c2f4a25c043fa84182188b5d702ec",
            "placeholder": "​",
            "style": "IPY_MODEL_8423b775e2e5495593f1c0806aa10255",
            "value": " 10000/10000 [00:15&lt;00:00, 772.47 examples/s]"
          }
        },
        "f6609149507f46afa81c577285157f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a395be316c2a427fb06095ff67f37b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0036d81ff68f4db1992493e9da22e90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7617b1129e534a5d9374eac67b71eb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2310f28d324181ad0ab4ab9561c32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f8c2f4a25c043fa84182188b5d702ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8423b775e2e5495593f1c0806aa10255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc8pkJe50w2R",
        "outputId": "10dda4a7-716a-4021-8bd4-0644b0255a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llmcompressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58r7Ek5H4qyI",
        "outputId": "30ed5f13-43ed-4e56-85cd-5ee708e536a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llmcompressor\n",
            "  Downloading llmcompressor-0.5.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting loguru (from llmcompressor)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (6.0.2)\n",
            "Collecting numpy<2.0,>=1.17.0 (from llmcompressor)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (2.6.0+cu124)\n",
            "Collecting transformers<4.50,>4.0 (from llmcompressor)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from llmcompressor)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate!=1.1.0,>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (1.5.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (12.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (11.1.0)\n",
            "Collecting compressed-tensors==0.9.3 (from llmcompressor)\n",
            "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from compressed-tensors==0.9.3->llmcompressor) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->llmcompressor) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>4.0->llmcompressor) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>4.0->llmcompressor) (0.21.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->llmcompressor)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (2.2.2)\n",
            "Collecting xxhash (from datasets->llmcompressor)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->llmcompressor)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (3.11.15)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->llmcompressor) (12.570.86)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.19.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (0.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->llmcompressor) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->llmcompressor) (1.17.0)\n",
            "Downloading llmcompressor-0.5.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.9/245.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, loguru, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, compressed-tensors, llmcompressor\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed compressed-tensors-0.9.3 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 llmcompressor-0.5.0 loguru-0.7.3 multiprocess-0.70.16 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.49.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==2.2.3\n",
        "\n",
        "!pip install peft==0.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lgtclsV4-qi",
        "outputId": "fabc9663-e2f0-437c-9cee-502bfe913f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==2.2.3\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmcompressor 0.5.0 requires numpy<2.0,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.3\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.49.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.14.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.14.0) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.14.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd  /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1HOUNdo5BDw",
        "outputId": "2a1e420e-f8d7-455e-ffdf-c573624833e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1TMMdJa5E9r",
        "outputId": "5e94df40-3118-4db5-ad93-cc5a349462a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.2.3\n",
            "Uninstalling numpy-2.2.3:\n",
            "  Successfully uninstalled numpy-2.2.3\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ2dmzrg5gUm",
        "outputId": "beb5ea26-6c19-4030-a35a-0f67a3b9fb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "from llmcompressor.modifiers.quantization import QuantizationModifier\n",
        "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
        "from llmcompressor.transformers import oneshot\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "KIqsHzG15mfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model_stub = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "model_name = model_stub.split(\"/\")[-1]\n",
        "\n",
        "num_samples = 128\n",
        "max_seq_len = 1024\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_stub)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_stub,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "884eb0767d7e40a3bbf66a5999e69838",
            "8a7dd1868c634c949cadd2140403a5fa",
            "674db16d35e84350a250b4ab05764df8",
            "ca9b87d94c8946ea9e6676dec97cea6a",
            "0bbe2adf7c764b94a18faf1094215d8b",
            "bfff6d5f0a854de1aab25af2f12a53d1",
            "e4bcb74f13d24f68961b1dda71c5eebf",
            "e3c8754ae8a74f3da6c39e8de37cb047",
            "0152508b81c14c68843d0fa1560e7fa7",
            "9a65067ba1f848f79c73ab5856e0ffb8",
            "d81015cd8c9f403f9499f43d2ba67a3d",
            "0d0a90cf8f254a1da58f55f97b7e089b",
            "77741ee5842b434a8a7a384dfd316a7d",
            "287162785adb45d59cc5ba79f44035db",
            "436a82e2aafa43bebd7c42e8cb59917c",
            "90a513bc4d3b444e811bbd7fd9ad4b88",
            "8644f0db9f3a493296e6da8ca9520342",
            "b23871e0084247eabeb130b43dcbe9dd",
            "18c34d1938c94b13b6436dc1e359327b",
            "791874deda7a44cda61976436e294112",
            "55a8dcd397f24aec88205ce248598320",
            "c3724bcae09a4551b8d82277b3fec3ff",
            "feef90c62eb84360afe521a5f569f712",
            "a7097e13efaa4cdaba8599980714350d",
            "cf45a13f650a4468a89b150f7cbfd06e",
            "e2e250e627744f6a85475697768303bd",
            "96ed6f23e9a04719be2b867c662481ac",
            "f592330855624f75aa333674299ac27b",
            "4be989b365844f77a9b325bbde755544",
            "3a9a83e470cf4b92b58aca925157f61e",
            "66f94418aa464eb884774e38eda2847c",
            "ee358fe9ddcf449eb6ee3fa289d6daac",
            "60c0f222ae8745a8ad5fe478139ec3f0",
            "4dad480860644e39be169310f7e6c139",
            "fbd36b8c843644db9f99ef49bb327c71",
            "ab07c1379a634d0eb65afb426362f5cd",
            "2f48fa7ea7c54b5b8d11948f4250f67b",
            "b7d068f9175a4911907331ca6f68ccac",
            "758d7ccf208f44598bcf21e8753e3a08",
            "0dab3a798ee94167b380b107b35d68b3",
            "dc9936d298a943f180ce21c83252cf3a",
            "101d0f4e64524729afbe2327f09ae195",
            "6ecb4958ff78453698b951e32bb45a3b",
            "964cdbe93f6d41048c943ec51c36269a",
            "e6ae142ed3ee46a9af9f6e9537e8c00c",
            "983c29f5322a4d32b4a74af37c5b4050",
            "28e266fd54c443099abfbdc6052a3dac",
            "14c8c8dd3e0b47c1bc1c58e6c0781c60",
            "51f8859ce3404f95ace404a98ae0a003",
            "3af6de3ff4204d42ae98ed82a73d1995",
            "52d570676df44180bddfae77c747206e",
            "504d9c84b9ce42bbbc13dfa17107ea28",
            "11141c9ba5e24266aa32ecfffcd97a09",
            "fc21e43deb61483cbf38ee21c963f02a",
            "a997cd221cae414aa8c02113d1130424"
          ]
        },
        "id": "00qcdHrj5pX0",
        "outputId": "41b030a5-cfa8-47d7-c11a-c8ec9e522a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884eb0767d7e40a3bbf66a5999e69838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d0a90cf8f254a1da58f55f97b7e089b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feef90c62eb84360afe521a5f569f712"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dad480860644e39be169310f7e6c139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6ae142ed3ee46a9af9f6e9537e8c00c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.base_model.layers[0].mlp.gate_proj.weight.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6A59X0P5sxy",
        "outputId": "30d76961-526a-4ead-b4ea-c74bd75c169d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_fn(example):\n",
        "  return {\"text\": tokenizer.apply_chat_template(\n",
        "      example[\"messages\"],\n",
        "      add_generation_prompt=False,\n",
        "      tokenize=False\n",
        "  )}\n",
        "ds = load_dataset(\"neuralmagic/LLM_compression_calibration\", split=\"train\")\n",
        "ds = ds.map(preprocess_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e5d68550764249f09145dc452caf2632",
            "09e8dd62ce554d4ca16411b3ad2c54d8",
            "7f336264099d4a039938d193f2c771b7",
            "30978dbb7515474cafb630c8a54c9fad",
            "5b17ba2ffe5440dfa2feaa7f2d519eb5",
            "2818ecbe415d46c7a4a301c5ac22b707",
            "b335361466f7471d956f9acef1c4d28e",
            "cd7358bb39e74503ae8ee2605c5976db",
            "ed807598acec40a08e872d177e3eedd7",
            "be32b36831f8427d8cb86c8f6e660a3a",
            "e3640ee45dc44265a53b8897f905a7ab",
            "6eea1fa0ec28476ca50a9078465357cd",
            "cbbc2a72e2864de782d8a33ad87f7c1d",
            "2f67e3159288469eb5ae57f3f731ec9b",
            "9b831923177449148c6012b0aaad10dd",
            "d56cea9955034b01a6d71b3510c16b37",
            "c08aa02d19f54bd7bc6a040fb2c3cffc",
            "bfcaa9206b3f463586dcb7f30372ae20",
            "94f85afb92bc418bae1452ebc6fa2833",
            "8019d71152b24f12b4512d75039028b8",
            "e13d5a2ae6c34910bb5c37cf09765122",
            "d8863d0df3c14c65afa41e93a9a02387",
            "a90192439eb5425790daedb20d0a5a5e",
            "9b417d518a7b419c9aa89fa99bf1e53d",
            "50ed6187a2e74781815876a9c9922681",
            "975ffa398e084b75b481baa9fad39f38",
            "a6fbc8df47e849e7aee851e4f70bab9f",
            "8dedd90e90e146b6bc87aee0a22d502a",
            "81adf07e79c349818e6f9fa72de9f96a",
            "222035718bef4eda85a9e7259207deac",
            "2e172991e2004e04b12c88f1f7c79e80",
            "c5ac48f6fbb64601960e48e81da35a91",
            "b0dd6757a18845539570a909cca27c96",
            "6d1ea06311fb46df8feb8488a5fff5c9",
            "bec217e3d2e441bc8786ad74956dfb2d",
            "92c2ef1f50c24028a1bce5de08ef600a",
            "32f43b06c01049b7b0be41b70e9323fe",
            "2764d69624f049e88674c048ba3186a3",
            "80d55ad139c9436295398d95fcc616ea",
            "fbcd38ab16fa4f2cb3bbad9db3ae6b67",
            "ef28e43943394c8d94c80ed78a242e67",
            "edb5c27e5de2449a8e008b314356965e",
            "f2f4e872e33d4fc29742682787761791",
            "f44a3ab46e164c99b03f1352514dbf93"
          ]
        },
        "id": "42EnEuiO5zc7",
        "outputId": "4ad855cf-b770-4d79-c07d-ed5b2d83db02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/832 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5d68550764249f09145dc452caf2632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "calibration.json.gz:   0%|          | 0.00/4.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eea1fa0ec28476ca50a9078465357cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a90192439eb5425790daedb20d0a5a5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d1ea06311fb46df8feb8488a5fff5c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QuantizationModifier(\n",
        "    targets=\"Linear\",\n",
        "    scheme=\"W4A16\",\n",
        "    ignore=[\"lm_head\"],\n",
        "    dampening_frac=0.1,\n",
        ")\n",
        "\n",
        "recipe = [\n",
        "    SmoothQuantModifier(smoothing_strength=0.8),\n",
        "    GPTQModifier(targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"]),\n",
        "]\n",
        "\n",
        "# Apply quantization.\n",
        "oneshot(\n",
        "    model=model,\n",
        "    dataset=ds,\n",
        "    recipe=recipe,\n",
        "    max_seq_length=max_seq_len,\n",
        "    num_calibration_samples=num_samples,\n",
        ")\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/CS594/\" + model_name + \"-gptqquantized.w4a16\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"Model and tokenizer saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3090e0463c64f558aff8b11aa9f88c1",
            "1d5f7282940343b7b5f0cd1c794fd5cd",
            "6fb0ab3d24f146008cda9ebfd6843f57",
            "dfd19c6f6b334c139e6b70c956c09509",
            "f6609149507f46afa81c577285157f3c",
            "a395be316c2a427fb06095ff67f37b41",
            "0036d81ff68f4db1992493e9da22e90e",
            "7617b1129e534a5d9374eac67b71eb0f",
            "4a2310f28d324181ad0ab4ab9561c32b",
            "0f8c2f4a25c043fa84182188b5d702ec",
            "8423b775e2e5495593f1c0806aa10255"
          ]
        },
        "id": "Bh6DkXBz53V2",
        "outputId": "ba991228-e79f-4776-80e8-10f4964b2756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e73586087ec3>:14: DeprecationWarning: `from llmcompressor.transformers import oneshot` is deprecated, please use `from llmcompressor import oneshot`.\n",
            "  oneshot(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3090e0463c64f558aff8b11aa9f88c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:41:46.929683+0000 | reset | INFO - Compression lifecycle reset\n",
            "2025-04-20T16:41:46.931049+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-04-20T16:41:46.958936+0000 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n",
            "2025-04-20T16:41:47.779986+0000 | _calibrate | INFO - Running SmoothQuantModifier calibration with 128 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128/128 [00:27<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:15.148540+0000 | _apply_smoothing | INFO - Smoothing activation scales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:15.406217+0000 | _check_build_quant_modifier | WARNING - GPTQ quantization is set to True without an active quantization modifier.\n",
            "2025-04-20T16:42:15.406882+0000 | _build_quant_modifier | INFO - Building quantization modifier with args: {'targets': 'Linear', 'scheme': 'W4A16', 'ignore': ['lm_head']}\n",
            "2025-04-20T16:42:15.445647+0000 | _check_calibration_data | INFO - Skipping QuantizationModifier calibration, it is not required for the provided quantization config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preparing intermediates cache: 100%|██████████| 128/128 [00:00<00:00, 661.21it/s]\n",
            "(1/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:19.968100+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:21.158620+0000 | compress | METRIC - time 1.19s\n",
            "2025-04-20T16:42:21.159372+0000 | compress | METRIC - error 2734.91\n",
            "2025-04-20T16:42:21.160432+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:21.160992+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:42:21.161882+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:42:22.063085+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:42:22.063804+0000 | compress | METRIC - error 256.82\n",
            "2025-04-20T16:42:22.064573+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:22.065145+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:22.066265+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:42:22.973107+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:42:22.973792+0000 | compress | METRIC - error 56.87\n",
            "2025-04-20T16:42:22.974545+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:22.975066+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:22.976149+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:42:23.893639+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:42:23.894359+0000 | compress | METRIC - error 518.26\n",
            "2025-04-20T16:42:23.895179+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:23.895945+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:42:23.896866+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:42:24.897910+0000 | compress | METRIC - time 1.00s\n",
            "2025-04-20T16:42:24.898848+0000 | compress | METRIC - error 1254.26\n",
            "2025-04-20T16:42:24.899703+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:24.900168+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:24.901401+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:42:25.875808+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:42:25.876870+0000 | compress | METRIC - error 920.80\n",
            "2025-04-20T16:42:25.877643+0000 | compress | METRIC - GPU 0 | usage: 22.39% | total memory: 42 GB\n",
            "2025-04-20T16:42:25.878233+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:25.879364+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:42:31.281223+0000 | compress | METRIC - time 5.40s\n",
            "2025-04-20T16:42:31.282157+0000 | compress | METRIC - error 380.92\n",
            "2025-04-20T16:42:31.282962+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:31.283412+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(1/29): Propagating: 100%|██████████| 128/128 [00:02<00:00, 56.94it/s]\n",
            "(2/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 44.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:36.383811+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:37.311387+0000 | compress | METRIC - time 0.93s\n",
            "2025-04-20T16:42:37.312184+0000 | compress | METRIC - error 480.26\n",
            "2025-04-20T16:42:37.313064+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:37.313614+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:42:37.314718+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:42:38.211129+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:42:38.211894+0000 | compress | METRIC - error 149.45\n",
            "2025-04-20T16:42:38.212690+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:38.213228+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:38.214206+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:42:39.108891+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:42:39.109677+0000 | compress | METRIC - error 35.03\n",
            "2025-04-20T16:42:39.110453+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:39.111201+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:39.112233+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:42:40.021983+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:42:40.022725+0000 | compress | METRIC - error 162.25\n",
            "2025-04-20T16:42:40.023332+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:40.023731+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:42:40.025032+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:42:41.004138+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:42:41.004826+0000 | compress | METRIC - error 30445.73\n",
            "2025-04-20T16:42:41.005554+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:41.006017+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:41.007089+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:42:41.993179+0000 | compress | METRIC - time 0.99s\n",
            "2025-04-20T16:42:41.993926+0000 | compress | METRIC - error 14450.77\n",
            "2025-04-20T16:42:41.994677+0000 | compress | METRIC - GPU 0 | usage: 23.14% | total memory: 42 GB\n",
            "2025-04-20T16:42:41.995174+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:41.996133+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:42:47.431144+0000 | compress | METRIC - time 5.43s\n",
            "2025-04-20T16:42:47.431935+0000 | compress | METRIC - error 79058.10\n",
            "2025-04-20T16:42:47.432831+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:47.433571+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(2/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 81.32it/s]\n",
            "(3/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:51.721758+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:42:52.639244+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:42:52.640266+0000 | compress | METRIC - error 1511.28\n",
            "2025-04-20T16:42:52.641036+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:52.641564+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:42:52.642585+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:42:53.530218+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:42:53.531019+0000 | compress | METRIC - error 364.20\n",
            "2025-04-20T16:42:53.531717+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:53.532332+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:53.533401+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:42:54.428920+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:42:54.429706+0000 | compress | METRIC - error 98.90\n",
            "2025-04-20T16:42:54.430369+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:54.430838+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:42:54.431951+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:42:55.334914+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:42:55.335741+0000 | compress | METRIC - error 105.50\n",
            "2025-04-20T16:42:55.336506+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:55.336984+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:42:55.338105+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:42:56.308728+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:42:56.309637+0000 | compress | METRIC - error 62684.95\n",
            "2025-04-20T16:42:56.310271+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:56.310683+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:56.311738+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:42:57.281174+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:42:57.281974+0000 | compress | METRIC - error 15777.99\n",
            "2025-04-20T16:42:57.282835+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:42:57.283344+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:42:57.284269+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:43:02.776575+0000 | compress | METRIC - time 5.49s\n",
            "2025-04-20T16:43:02.777447+0000 | compress | METRIC - error 9653462.00\n",
            "2025-04-20T16:43:02.778268+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:02.778686+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(3/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.11it/s]\n",
            "(4/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:06.927937+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:07.838420+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:43:07.839283+0000 | compress | METRIC - error 1620.34\n",
            "2025-04-20T16:43:07.840010+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:07.840427+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:43:07.841454+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:43:08.733150+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:43:08.734020+0000 | compress | METRIC - error 411.59\n",
            "2025-04-20T16:43:08.734705+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:08.735093+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:08.736062+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:43:09.633510+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:09.634398+0000 | compress | METRIC - error 138.17\n",
            "2025-04-20T16:43:09.635129+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:09.635565+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:09.636757+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:43:10.544167+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:43:10.545156+0000 | compress | METRIC - error 26.29\n",
            "2025-04-20T16:43:10.546149+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:10.546785+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:43:10.547964+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:43:11.528226+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:43:11.529013+0000 | compress | METRIC - error 73948.67\n",
            "2025-04-20T16:43:11.529709+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:11.530165+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:11.530986+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:43:12.527152+0000 | compress | METRIC - time 1.00s\n",
            "2025-04-20T16:43:12.528022+0000 | compress | METRIC - error 12000.97\n",
            "2025-04-20T16:43:12.528798+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:12.529358+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:12.530369+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:43:17.997879+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:43:17.998655+0000 | compress | METRIC - error 701.36\n",
            "2025-04-20T16:43:17.999666+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:18.000169+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(4/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.76it/s]\n",
            "(5/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:22.138086+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:23.054878+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:43:23.055693+0000 | compress | METRIC - error 2207.14\n",
            "2025-04-20T16:43:23.056730+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:23.057338+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:43:23.058545+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:43:23.947094+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:43:23.947743+0000 | compress | METRIC - error 521.71\n",
            "2025-04-20T16:43:23.948726+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:23.949558+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:23.950466+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:43:24.855684+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:24.856570+0000 | compress | METRIC - error 181.38\n",
            "2025-04-20T16:43:24.857253+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:24.857873+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:24.859071+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:43:25.763935+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:25.764661+0000 | compress | METRIC - error 349.39\n",
            "2025-04-20T16:43:25.765468+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:25.766095+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:43:25.767192+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:43:26.747003+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:43:26.747930+0000 | compress | METRIC - error 32797.99\n",
            "2025-04-20T16:43:26.748629+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:26.749064+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:26.750041+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:43:27.725518+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:43:27.726341+0000 | compress | METRIC - error 7634.72\n",
            "2025-04-20T16:43:27.727108+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:27.727568+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:27.728605+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:43:33.197187+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:43:33.198195+0000 | compress | METRIC - error 1920.82\n",
            "2025-04-20T16:43:33.198978+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:33.199486+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(5/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.97it/s]\n",
            "(6/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:37.354569+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:38.318443+0000 | compress | METRIC - time 0.96s\n",
            "2025-04-20T16:43:38.319324+0000 | compress | METRIC - error 2678.91\n",
            "2025-04-20T16:43:38.320388+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:38.321067+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:43:38.322111+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:43:39.210671+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:43:39.211329+0000 | compress | METRIC - error 712.19\n",
            "2025-04-20T16:43:39.212125+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:39.212577+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:39.213523+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:43:40.106414+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:43:40.107134+0000 | compress | METRIC - error 301.95\n",
            "2025-04-20T16:43:40.107882+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:40.108428+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:40.109400+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:43:41.008398+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:41.009126+0000 | compress | METRIC - error 213.72\n",
            "2025-04-20T16:43:41.009941+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:41.010456+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:43:41.011486+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:43:41.985956+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:43:41.986650+0000 | compress | METRIC - error 114533.17\n",
            "2025-04-20T16:43:41.987229+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:41.987655+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:41.988572+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:43:42.970273+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:43:42.970991+0000 | compress | METRIC - error 23203.77\n",
            "2025-04-20T16:43:42.971749+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:42.972323+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:42.973383+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:43:48.442856+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:43:48.443749+0000 | compress | METRIC - error 1171.35\n",
            "2025-04-20T16:43:48.444573+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:48.445036+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(6/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.14it/s]\n",
            "(7/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:52.612984+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:43:53.524311+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:43:53.525143+0000 | compress | METRIC - error 3375.22\n",
            "2025-04-20T16:43:53.526025+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:53.526539+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:43:53.527512+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:43:54.418953+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:43:54.419743+0000 | compress | METRIC - error 858.08\n",
            "2025-04-20T16:43:54.420486+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:54.420939+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:54.421922+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:43:55.317738+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:55.318477+0000 | compress | METRIC - error 222.52\n",
            "2025-04-20T16:43:55.319242+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:55.319820+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:43:55.320977+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:43:56.225524+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:43:56.226415+0000 | compress | METRIC - error 183.37\n",
            "2025-04-20T16:43:56.227419+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:56.227965+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:43:56.229038+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:43:57.205616+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:43:57.206345+0000 | compress | METRIC - error 13568.76\n",
            "2025-04-20T16:43:57.207079+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:57.207507+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:57.208652+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:43:58.182668+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:43:58.183435+0000 | compress | METRIC - error 7734.48\n",
            "2025-04-20T16:43:58.184317+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:43:58.184841+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:43:58.186016+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:44:03.672216+0000 | compress | METRIC - time 5.49s\n",
            "2025-04-20T16:44:03.673025+0000 | compress | METRIC - error 1593.27\n",
            "2025-04-20T16:44:03.673790+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:03.674253+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(7/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.47it/s]\n",
            "(8/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:07.817154+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:08.731356+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:08.732082+0000 | compress | METRIC - error 1845.17\n",
            "2025-04-20T16:44:08.732825+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:08.733547+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:44:08.734560+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:44:09.623093+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:09.624047+0000 | compress | METRIC - error 454.33\n",
            "2025-04-20T16:44:09.624790+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:09.625275+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:09.626271+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:44:10.517672+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:10.518437+0000 | compress | METRIC - error 213.41\n",
            "2025-04-20T16:44:10.519159+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:10.519832+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:10.520807+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:44:11.427519+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:11.428328+0000 | compress | METRIC - error 595.05\n",
            "2025-04-20T16:44:11.429069+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:11.429470+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:44:11.430451+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:44:12.414488+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:44:12.415504+0000 | compress | METRIC - error 12119.67\n",
            "2025-04-20T16:44:12.416387+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:12.416889+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:12.418023+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:44:13.397927+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:44:13.398804+0000 | compress | METRIC - error 8582.05\n",
            "2025-04-20T16:44:13.399605+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:13.400503+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:13.401436+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:44:18.883172+0000 | compress | METRIC - time 5.48s\n",
            "2025-04-20T16:44:18.884142+0000 | compress | METRIC - error 2077.89\n",
            "2025-04-20T16:44:18.884876+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:18.885313+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(8/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.36it/s]\n",
            "(9/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:23.031413+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:23.940680+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:23.941407+0000 | compress | METRIC - error 4191.09\n",
            "2025-04-20T16:44:23.942185+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:23.942861+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:44:23.944009+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:44:24.835413+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:24.836365+0000 | compress | METRIC - error 936.73\n",
            "2025-04-20T16:44:24.837013+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:24.837583+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:24.838988+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:44:25.757058+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:44:25.757986+0000 | compress | METRIC - error 256.69\n",
            "2025-04-20T16:44:25.758717+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:25.759190+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:25.760277+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:44:26.659227+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:44:26.660094+0000 | compress | METRIC - error 518.54\n",
            "2025-04-20T16:44:26.660822+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:26.661265+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:44:26.662506+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:44:27.633710+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:44:27.634602+0000 | compress | METRIC - error 13655.80\n",
            "2025-04-20T16:44:27.635414+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:27.636049+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:27.637424+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:44:28.593198+0000 | compress | METRIC - time 0.96s\n",
            "2025-04-20T16:44:28.594021+0000 | compress | METRIC - error 9767.34\n",
            "2025-04-20T16:44:28.594733+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:28.595239+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:28.596182+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:44:34.042406+0000 | compress | METRIC - time 5.45s\n",
            "2025-04-20T16:44:34.043167+0000 | compress | METRIC - error 2055.73\n",
            "2025-04-20T16:44:34.043948+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:34.044460+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(9/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.39it/s]\n",
            "(10/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:38.189615+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:39.104399+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:39.105147+0000 | compress | METRIC - error 3202.18\n",
            "2025-04-20T16:44:39.105966+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:39.106504+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:44:39.107383+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:44:39.995302+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:39.995980+0000 | compress | METRIC - error 716.25\n",
            "2025-04-20T16:44:39.996702+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:39.997107+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:39.998216+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:44:40.891976+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:40.892651+0000 | compress | METRIC - error 249.61\n",
            "2025-04-20T16:44:40.893406+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:40.893947+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:40.895211+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:44:41.802990+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:41.803678+0000 | compress | METRIC - error 932.30\n",
            "2025-04-20T16:44:41.804382+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:41.804775+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:44:41.805704+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:44:42.782654+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:44:42.783536+0000 | compress | METRIC - error 12345.72\n",
            "2025-04-20T16:44:42.784243+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:42.784641+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:42.785721+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:44:43.762758+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:44:43.763678+0000 | compress | METRIC - error 10031.19\n",
            "2025-04-20T16:44:43.764471+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:43.765266+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:43.766266+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:44:49.211786+0000 | compress | METRIC - time 5.44s\n",
            "2025-04-20T16:44:49.212532+0000 | compress | METRIC - error 2048.81\n",
            "2025-04-20T16:44:49.213281+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:49.213702+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(10/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.94it/s]\n",
            "(11/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:53.367185+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:44:54.285855+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:44:54.286633+0000 | compress | METRIC - error 4000.53\n",
            "2025-04-20T16:44:54.287179+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:54.287850+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:44:54.289132+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:44:55.182325+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:44:55.183218+0000 | compress | METRIC - error 909.97\n",
            "2025-04-20T16:44:55.183954+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:55.184637+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:55.185865+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:44:56.082303+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:44:56.083026+0000 | compress | METRIC - error 383.18\n",
            "2025-04-20T16:44:56.083912+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:56.084445+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:44:56.085691+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:44:56.996563+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:44:56.997320+0000 | compress | METRIC - error 903.40\n",
            "2025-04-20T16:44:56.998239+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:56.998799+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:44:57.000015+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:44:57.974920+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:44:57.975811+0000 | compress | METRIC - error 12282.79\n",
            "2025-04-20T16:44:57.976721+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:57.977311+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:57.978301+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:44:58.958295+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:44:58.958958+0000 | compress | METRIC - error 9904.43\n",
            "2025-04-20T16:44:58.959771+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:44:58.960226+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:44:58.961181+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:45:04.454322+0000 | compress | METRIC - time 5.49s\n",
            "2025-04-20T16:45:04.455213+0000 | compress | METRIC - error 1826.52\n",
            "2025-04-20T16:45:04.455988+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:04.456433+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(11/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.02it/s]\n",
            "(12/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:08.607962+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:09.527345+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:45:09.528265+0000 | compress | METRIC - error 3445.14\n",
            "2025-04-20T16:45:09.528969+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:09.529532+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:45:09.530648+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:45:10.435073+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:45:10.435909+0000 | compress | METRIC - error 713.83\n",
            "2025-04-20T16:45:10.436717+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:10.437300+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:10.438377+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:45:11.330142+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:45:11.330915+0000 | compress | METRIC - error 309.27\n",
            "2025-04-20T16:45:11.331745+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:11.332224+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:11.333316+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:45:12.248850+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:45:12.249689+0000 | compress | METRIC - error 994.87\n",
            "2025-04-20T16:45:12.250463+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:12.251050+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:45:12.251930+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:45:13.269855+0000 | compress | METRIC - time 1.02s\n",
            "2025-04-20T16:45:13.270685+0000 | compress | METRIC - error 12941.48\n",
            "2025-04-20T16:45:13.271474+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:13.271941+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:13.273228+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:45:14.295604+0000 | compress | METRIC - time 1.02s\n",
            "2025-04-20T16:45:14.296371+0000 | compress | METRIC - error 9382.82\n",
            "2025-04-20T16:45:14.296893+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:14.297506+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:14.298980+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:45:19.756919+0000 | compress | METRIC - time 5.46s\n",
            "2025-04-20T16:45:19.757902+0000 | compress | METRIC - error 1649.71\n",
            "2025-04-20T16:45:19.758451+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:19.758903+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(12/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.29it/s]\n",
            "(13/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:23.905823+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:24.822244+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:45:24.822983+0000 | compress | METRIC - error 4457.11\n",
            "2025-04-20T16:45:24.823747+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:24.824325+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:45:24.825289+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:45:25.709848+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:45:25.710768+0000 | compress | METRIC - error 1044.17\n",
            "2025-04-20T16:45:25.711545+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:25.712245+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:25.713304+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:45:26.618104+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:45:26.618973+0000 | compress | METRIC - error 353.69\n",
            "2025-04-20T16:45:26.619681+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:26.620101+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:26.621082+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:45:27.525951+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:45:27.526753+0000 | compress | METRIC - error 580.26\n",
            "2025-04-20T16:45:27.527461+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:27.527884+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:45:27.528899+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:45:28.504305+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:45:28.505187+0000 | compress | METRIC - error 11181.83\n",
            "2025-04-20T16:45:28.505885+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:28.506296+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:28.507389+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:45:29.492332+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:45:29.493114+0000 | compress | METRIC - error 9431.65\n",
            "2025-04-20T16:45:29.493830+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:29.494286+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:29.495274+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:45:34.957235+0000 | compress | METRIC - time 5.46s\n",
            "2025-04-20T16:45:34.958386+0000 | compress | METRIC - error 1811.37\n",
            "2025-04-20T16:45:34.959169+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:34.959796+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(13/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.28it/s]\n",
            "(14/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:39.106317+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:40.016826+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:45:40.017526+0000 | compress | METRIC - error 2603.06\n",
            "2025-04-20T16:45:40.018255+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:40.018771+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:45:40.019808+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:45:40.898122+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:45:40.898807+0000 | compress | METRIC - error 681.53\n",
            "2025-04-20T16:45:40.899724+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:40.900315+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:40.901551+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:45:41.787344+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:45:41.788238+0000 | compress | METRIC - error 285.47\n",
            "2025-04-20T16:45:41.789039+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:41.789650+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:41.791052+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:45:42.694288+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:45:42.695197+0000 | compress | METRIC - error 757.11\n",
            "2025-04-20T16:45:42.696280+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:42.696920+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:45:42.698181+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:45:43.681302+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:45:43.682245+0000 | compress | METRIC - error 9759.17\n",
            "2025-04-20T16:45:43.683165+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:43.683792+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:43.684982+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:45:44.657550+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:45:44.658433+0000 | compress | METRIC - error 9043.12\n",
            "2025-04-20T16:45:44.659324+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:44.659991+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:44.661231+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:45:50.176764+0000 | compress | METRIC - time 5.51s\n",
            "2025-04-20T16:45:50.177566+0000 | compress | METRIC - error 1591.51\n",
            "2025-04-20T16:45:50.178393+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:50.179039+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(14/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.47it/s]\n",
            "(15/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:54.324185+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:45:55.241941+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:45:55.242756+0000 | compress | METRIC - error 6337.81\n",
            "2025-04-20T16:45:55.243639+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:55.244167+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:45:55.245228+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:45:56.136467+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:45:56.137348+0000 | compress | METRIC - error 1273.11\n",
            "2025-04-20T16:45:56.138285+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:56.138913+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:56.140134+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:45:57.037581+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:45:57.038265+0000 | compress | METRIC - error 498.83\n",
            "2025-04-20T16:45:57.039044+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:57.039612+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:45:57.040727+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:45:57.933709+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:45:57.934426+0000 | compress | METRIC - error 442.70\n",
            "2025-04-20T16:45:57.935222+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:57.935778+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:45:57.936855+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:45:58.913996+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:45:58.914750+0000 | compress | METRIC - error 11022.38\n",
            "2025-04-20T16:45:58.915567+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:58.916123+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:58.917232+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:45:59.901923+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:45:59.902829+0000 | compress | METRIC - error 10545.15\n",
            "2025-04-20T16:45:59.903629+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:45:59.904038+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:45:59.905015+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:46:05.504455+0000 | compress | METRIC - time 5.60s\n",
            "2025-04-20T16:46:05.505342+0000 | compress | METRIC - error 2187.17\n",
            "2025-04-20T16:46:05.506076+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:05.506522+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(15/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.45it/s]\n",
            "(16/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:09.649010+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:10.563934+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:46:10.564815+0000 | compress | METRIC - error 3908.25\n",
            "2025-04-20T16:46:10.565739+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:10.566319+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:46:10.567506+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:46:11.455854+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:46:11.456672+0000 | compress | METRIC - error 798.73\n",
            "2025-04-20T16:46:11.457407+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:11.457927+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:11.458792+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:46:12.364213+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:46:12.365053+0000 | compress | METRIC - error 486.16\n",
            "2025-04-20T16:46:12.365952+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:12.366555+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:12.367712+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:46:13.280522+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:46:13.281316+0000 | compress | METRIC - error 1684.63\n",
            "2025-04-20T16:46:13.282115+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:13.282643+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:46:13.283639+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:46:14.275840+0000 | compress | METRIC - time 0.99s\n",
            "2025-04-20T16:46:14.276658+0000 | compress | METRIC - error 10925.77\n",
            "2025-04-20T16:46:14.277476+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:14.277988+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:14.279111+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:46:15.257301+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:46:15.258065+0000 | compress | METRIC - error 9291.78\n",
            "2025-04-20T16:46:15.259095+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:15.259691+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:15.260783+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:46:20.728749+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:46:20.729684+0000 | compress | METRIC - error 1702.00\n",
            "2025-04-20T16:46:20.730433+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:20.730930+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(16/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.39it/s]\n",
            "(17/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:24.878781+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:25.795818+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:46:25.796934+0000 | compress | METRIC - error 4584.06\n",
            "2025-04-20T16:46:25.798045+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:25.798697+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:46:25.799756+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:46:26.687159+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:46:26.688075+0000 | compress | METRIC - error 1197.50\n",
            "2025-04-20T16:46:26.688805+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:26.689235+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:26.690292+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:46:27.583116+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:46:27.583980+0000 | compress | METRIC - error 502.92\n",
            "2025-04-20T16:46:27.584745+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:27.585319+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:27.586345+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:46:28.491981+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:46:28.492894+0000 | compress | METRIC - error 660.38\n",
            "2025-04-20T16:46:28.493888+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:28.494443+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:46:28.495596+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:46:29.472144+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:46:29.473022+0000 | compress | METRIC - error 12601.24\n",
            "2025-04-20T16:46:29.473977+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:29.474566+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:29.475572+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:46:30.459744+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:46:30.460744+0000 | compress | METRIC - error 10435.89\n",
            "2025-04-20T16:46:30.461772+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:30.462288+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:30.463370+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:46:35.945684+0000 | compress | METRIC - time 5.48s\n",
            "2025-04-20T16:46:35.946471+0000 | compress | METRIC - error 2218.24\n",
            "2025-04-20T16:46:35.947143+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:35.947570+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(17/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.91it/s]\n",
            "(18/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:40.099215+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:41.011129+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:46:41.011839+0000 | compress | METRIC - error 4401.95\n",
            "2025-04-20T16:46:41.012411+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:41.012796+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:46:41.013852+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:46:41.907230+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:46:41.908252+0000 | compress | METRIC - error 954.76\n",
            "2025-04-20T16:46:41.909065+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:41.909647+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:41.910654+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:46:42.809186+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:46:42.810141+0000 | compress | METRIC - error 508.16\n",
            "2025-04-20T16:46:42.810838+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:42.811609+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:42.812433+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:46:43.733460+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:46:43.734460+0000 | compress | METRIC - error 574.67\n",
            "2025-04-20T16:46:43.735459+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:43.735991+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:46:43.737096+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:46:44.720974+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:46:44.721971+0000 | compress | METRIC - error 14126.55\n",
            "2025-04-20T16:46:44.723106+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:44.723713+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:44.724832+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:46:45.703660+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:46:45.704622+0000 | compress | METRIC - error 10776.15\n",
            "2025-04-20T16:46:45.705623+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:45.706125+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:45.707215+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:46:51.227901+0000 | compress | METRIC - time 5.52s\n",
            "2025-04-20T16:46:51.228799+0000 | compress | METRIC - error 2789.65\n",
            "2025-04-20T16:46:51.229809+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:51.230302+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(18/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.16it/s]\n",
            "(19/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:55.379725+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:46:56.293223+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:46:56.293956+0000 | compress | METRIC - error 3547.61\n",
            "2025-04-20T16:46:56.294590+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:56.294971+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:46:56.296050+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:46:57.180431+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:46:57.181222+0000 | compress | METRIC - error 978.92\n",
            "2025-04-20T16:46:57.181918+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:57.182386+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:57.183254+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:46:58.071119+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:46:58.071833+0000 | compress | METRIC - error 509.39\n",
            "2025-04-20T16:46:58.072602+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:58.073055+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:46:58.074151+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:46:58.979362+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:46:58.980093+0000 | compress | METRIC - error 728.05\n",
            "2025-04-20T16:46:58.981201+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:58.981888+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:46:58.982890+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:46:59.953359+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:46:59.954220+0000 | compress | METRIC - error 15743.79\n",
            "2025-04-20T16:46:59.955313+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:46:59.955920+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:46:59.957016+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:47:00.932245+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:00.933209+0000 | compress | METRIC - error 12202.74\n",
            "2025-04-20T16:47:00.934239+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:00.934869+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:00.936075+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:47:06.397191+0000 | compress | METRIC - time 5.46s\n",
            "2025-04-20T16:47:06.398072+0000 | compress | METRIC - error 3707.85\n",
            "2025-04-20T16:47:06.398910+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:06.399483+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(19/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 90.30it/s]\n",
            "(20/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:10.530228+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:11.442658+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:11.443580+0000 | compress | METRIC - error 4347.35\n",
            "2025-04-20T16:47:11.444591+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:11.445235+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:47:11.446285+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:47:12.337694+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:12.338541+0000 | compress | METRIC - error 1165.12\n",
            "2025-04-20T16:47:12.339268+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:12.339687+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:12.340623+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:47:13.221967+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:47:13.222811+0000 | compress | METRIC - error 843.67\n",
            "2025-04-20T16:47:13.223643+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:13.224229+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:13.225074+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:47:14.132433+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:14.133223+0000 | compress | METRIC - error 1306.88\n",
            "2025-04-20T16:47:14.133982+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:14.134563+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:47:14.135647+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:47:15.105596+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:15.106413+0000 | compress | METRIC - error 20370.42\n",
            "2025-04-20T16:47:15.107369+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:15.107873+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:15.108923+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:47:16.083826+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:16.084691+0000 | compress | METRIC - error 15352.23\n",
            "2025-04-20T16:47:16.085675+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:16.086308+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:16.087366+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:47:21.556081+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:47:21.556952+0000 | compress | METRIC - error 6614.15\n",
            "2025-04-20T16:47:21.557767+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:21.558203+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(20/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.82it/s]\n",
            "(21/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:25.712631+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:26.625667+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:26.626627+0000 | compress | METRIC - error 4771.70\n",
            "2025-04-20T16:47:26.627517+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:26.628003+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:47:26.629050+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:47:27.505893+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:47:27.506844+0000 | compress | METRIC - error 1563.92\n",
            "2025-04-20T16:47:27.507462+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:27.507967+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:27.508939+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:47:28.398035+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:28.398914+0000 | compress | METRIC - error 1435.75\n",
            "2025-04-20T16:47:28.399726+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:28.400264+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:28.401415+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:47:29.316068+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:29.316910+0000 | compress | METRIC - error 2226.49\n",
            "2025-04-20T16:47:29.317867+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:29.318438+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:47:29.319555+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:47:30.288628+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:30.289462+0000 | compress | METRIC - error 24089.11\n",
            "2025-04-20T16:47:30.290192+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:30.290951+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:30.291852+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:47:31.266631+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:31.267391+0000 | compress | METRIC - error 16774.14\n",
            "2025-04-20T16:47:31.268107+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:31.268605+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:31.269637+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:47:36.703441+0000 | compress | METRIC - time 5.43s\n",
            "2025-04-20T16:47:36.704612+0000 | compress | METRIC - error 6282.39\n",
            "2025-04-20T16:47:36.705291+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:36.705788+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(21/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.18it/s]\n",
            "(22/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:40.852357+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:41.765014+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:41.765961+0000 | compress | METRIC - error 5032.00\n",
            "2025-04-20T16:47:41.766761+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:41.767334+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:47:41.768345+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:47:42.656550+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:42.657434+0000 | compress | METRIC - error 1234.54\n",
            "2025-04-20T16:47:42.658187+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:42.658613+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:42.659941+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:47:43.551585+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:43.552447+0000 | compress | METRIC - error 1178.13\n",
            "2025-04-20T16:47:43.553146+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:43.553660+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:43.554892+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:47:44.466336+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:44.467202+0000 | compress | METRIC - error 1602.68\n",
            "2025-04-20T16:47:44.468128+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:44.468644+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:47:44.469607+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:47:45.444414+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:47:45.445206+0000 | compress | METRIC - error 34726.70\n",
            "2025-04-20T16:47:45.445950+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:45.446400+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:45.447457+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:47:46.425703+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:47:46.426537+0000 | compress | METRIC - error 23221.64\n",
            "2025-04-20T16:47:46.427272+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:46.427692+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:47:46.428832+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:47:51.966331+0000 | compress | METRIC - time 5.54s\n",
            "2025-04-20T16:47:51.967077+0000 | compress | METRIC - error 10800.07\n",
            "2025-04-20T16:47:51.967845+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:51.968270+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(22/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.22it/s]\n",
            "(23/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:56.114616+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:47:57.029998+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:47:57.030760+0000 | compress | METRIC - error 4049.17\n",
            "2025-04-20T16:47:57.031467+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:57.032068+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:47:57.033556+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:47:57.920971+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:57.921680+0000 | compress | METRIC - error 1177.33\n",
            "2025-04-20T16:47:57.922680+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:57.923235+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:57.924477+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:47:58.818717+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:47:58.819412+0000 | compress | METRIC - error 2137.12\n",
            "2025-04-20T16:47:58.820149+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:58.820742+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:47:58.821951+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:47:59.727411+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:47:59.728287+0000 | compress | METRIC - error 2297.48\n",
            "2025-04-20T16:47:59.729159+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:47:59.729761+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:47:59.730894+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:48:00.705300+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:48:00.706349+0000 | compress | METRIC - error 43286.20\n",
            "2025-04-20T16:48:00.707064+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:00.707690+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:00.708851+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:48:01.678363+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:48:01.679328+0000 | compress | METRIC - error 27566.61\n",
            "2025-04-20T16:48:01.680355+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:01.681099+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:01.682326+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:48:07.130467+0000 | compress | METRIC - time 5.45s\n",
            "2025-04-20T16:48:07.131239+0000 | compress | METRIC - error 13934.66\n",
            "2025-04-20T16:48:07.131993+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:07.132476+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(23/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.94it/s]\n",
            "(24/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:11.269919+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:12.188148+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:48:12.188933+0000 | compress | METRIC - error 5245.03\n",
            "2025-04-20T16:48:12.189641+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:12.190067+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:48:12.191157+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:48:13.079751+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:13.080675+0000 | compress | METRIC - error 1541.16\n",
            "2025-04-20T16:48:13.081285+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:13.081725+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:13.082673+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:48:13.978182+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:13.978972+0000 | compress | METRIC - error 3097.88\n",
            "2025-04-20T16:48:13.979872+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:13.980507+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:13.981620+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:48:14.882809+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:48:14.883747+0000 | compress | METRIC - error 1750.06\n",
            "2025-04-20T16:48:14.884506+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:14.884922+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:48:14.886134+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:48:15.860303+0000 | compress | METRIC - time 0.97s\n",
            "2025-04-20T16:48:15.861001+0000 | compress | METRIC - error 53196.04\n",
            "2025-04-20T16:48:15.861811+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:15.862302+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:15.863206+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:48:16.839954+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:48:16.840768+0000 | compress | METRIC - error 32109.09\n",
            "2025-04-20T16:48:16.841641+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:16.842456+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:16.843104+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:48:22.303597+0000 | compress | METRIC - time 5.46s\n",
            "2025-04-20T16:48:22.304372+0000 | compress | METRIC - error 15903.55\n",
            "2025-04-20T16:48:22.305155+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:22.305603+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(24/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.05it/s]\n",
            "(25/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:26.457583+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:27.369905+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:48:27.370792+0000 | compress | METRIC - error 4840.65\n",
            "2025-04-20T16:48:27.371781+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:27.372309+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:48:27.373363+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:48:28.263606+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:28.264475+0000 | compress | METRIC - error 1170.45\n",
            "2025-04-20T16:48:28.265464+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:28.265968+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:28.267086+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:48:29.161722+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:29.162575+0000 | compress | METRIC - error 4644.46\n",
            "2025-04-20T16:48:29.163580+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:29.164090+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:29.165172+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:48:30.073106+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:48:30.073866+0000 | compress | METRIC - error 2658.27\n",
            "2025-04-20T16:48:30.074616+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:30.075101+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:48:30.076380+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:48:31.056181+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:48:31.056938+0000 | compress | METRIC - error 49590.52\n",
            "2025-04-20T16:48:31.057509+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:31.058084+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:31.059425+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:48:32.039871+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:48:32.040647+0000 | compress | METRIC - error 33543.97\n",
            "2025-04-20T16:48:32.041478+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:32.042064+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:32.043118+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:48:37.525325+0000 | compress | METRIC - time 5.48s\n",
            "2025-04-20T16:48:37.526711+0000 | compress | METRIC - error 19106.93\n",
            "2025-04-20T16:48:37.527656+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:37.528102+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(25/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.85it/s]\n",
            "(26/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:41.682379+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:42.600753+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:48:42.601587+0000 | compress | METRIC - error 3101.27\n",
            "2025-04-20T16:48:42.602505+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:42.603177+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:48:42.604058+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:48:43.489444+0000 | compress | METRIC - time 0.88s\n",
            "2025-04-20T16:48:43.490254+0000 | compress | METRIC - error 940.73\n",
            "2025-04-20T16:48:43.490977+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:43.491660+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:43.492438+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:48:44.393523+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:48:44.394308+0000 | compress | METRIC - error 7205.95\n",
            "2025-04-20T16:48:44.394916+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:44.395337+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:44.396593+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:48:45.308129+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:48:45.309063+0000 | compress | METRIC - error 1229.11\n",
            "2025-04-20T16:48:45.309870+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:45.310391+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:48:45.311393+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:48:46.287568+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:48:46.288320+0000 | compress | METRIC - error 46229.44\n",
            "2025-04-20T16:48:46.289042+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:46.289422+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:46.290598+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:48:47.269117+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:48:47.269914+0000 | compress | METRIC - error 36378.13\n",
            "2025-04-20T16:48:47.270652+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:47.271131+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:48:47.272063+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:48:52.737744+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:48:52.738697+0000 | compress | METRIC - error 32440.77\n",
            "2025-04-20T16:48:52.739423+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:52.739829+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(26/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.61it/s]\n",
            "(27/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:56.882056+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:48:57.795072+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:48:57.795961+0000 | compress | METRIC - error 5149.05\n",
            "2025-04-20T16:48:57.796475+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:57.797058+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:48:57.798225+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:48:58.686603+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:58.687402+0000 | compress | METRIC - error 1158.63\n",
            "2025-04-20T16:48:58.688128+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:58.688846+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:58.689759+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:48:59.583477+0000 | compress | METRIC - time 0.89s\n",
            "2025-04-20T16:48:59.584319+0000 | compress | METRIC - error 10486.33\n",
            "2025-04-20T16:48:59.584864+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:48:59.585249+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:48:59.586303+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:49:00.493848+0000 | compress | METRIC - time 0.91s\n",
            "2025-04-20T16:49:00.494814+0000 | compress | METRIC - error 1333.22\n",
            "2025-04-20T16:49:00.495519+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:00.496025+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:49:00.497217+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:49:01.477706+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:49:01.478625+0000 | compress | METRIC - error 48001.46\n",
            "2025-04-20T16:49:01.479482+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:01.479997+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:49:01.481199+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:49:02.476103+0000 | compress | METRIC - time 0.99s\n",
            "2025-04-20T16:49:02.476945+0000 | compress | METRIC - error 39794.80\n",
            "2025-04-20T16:49:02.477650+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:02.478128+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:49:02.479005+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:49:07.945584+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:49:07.946291+0000 | compress | METRIC - error 1571412.25\n",
            "2025-04-20T16:49:07.947055+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:07.947607+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(27/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.18it/s]\n",
            "(28/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:49:12.095849+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:49:13.013943+0000 | compress | METRIC - time 0.92s\n",
            "2025-04-20T16:49:13.014697+0000 | compress | METRIC - error 5075.15\n",
            "2025-04-20T16:49:13.015620+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:13.016125+0000 | compress | METRIC - Compressed module size: 9.535488 MB\n",
            "2025-04-20T16:49:13.017304+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.k_proj using 128 samples\n",
            "2025-04-20T16:49:13.915015+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:49:13.915752+0000 | compress | METRIC - error 1148.35\n",
            "2025-04-20T16:49:13.916460+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:13.916931+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:49:13.918190+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.v_proj using 128 samples\n",
            "2025-04-20T16:49:14.817592+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:49:14.818283+0000 | compress | METRIC - error 10926.48\n",
            "2025-04-20T16:49:14.818987+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:14.819682+0000 | compress | METRIC - Compressed module size: 1.589248 MB\n",
            "2025-04-20T16:49:14.820733+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.o_proj using 128 samples\n",
            "2025-04-20T16:49:15.717360+0000 | compress | METRIC - time 0.90s\n",
            "2025-04-20T16:49:15.718386+0000 | compress | METRIC - error 9431.51\n",
            "2025-04-20T16:49:15.719105+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:15.719684+0000 | compress | METRIC - Compressed module size: 9.529344 MB\n",
            "2025-04-20T16:49:15.720798+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.gate_proj using 128 samples\n",
            "2025-04-20T16:49:16.702414+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:49:16.703354+0000 | compress | METRIC - error 80157.70\n",
            "2025-04-20T16:49:16.704132+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:16.704722+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:49:16.705944+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.up_proj using 128 samples\n",
            "2025-04-20T16:49:17.683057+0000 | compress | METRIC - time 0.98s\n",
            "2025-04-20T16:49:17.684008+0000 | compress | METRIC - error 63305.30\n",
            "2025-04-20T16:49:17.684989+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:17.685571+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n",
            "2025-04-20T16:49:17.686566+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.down_proj using 128 samples\n",
            "2025-04-20T16:49:23.159249+0000 | compress | METRIC - time 5.47s\n",
            "2025-04-20T16:49:23.159999+0000 | compress | METRIC - error 163229.16\n",
            "2025-04-20T16:49:23.160714+0000 | compress | METRIC - GPU 0 | usage: 23.89% | total memory: 42 GB\n",
            "2025-04-20T16:49:23.161172+0000 | compress | METRIC - Compressed module size: 55.58784 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(28/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.71it/s]\n",
            "(29/29): Calibrating: 100%|██████████| 128/128 [00:03<00:00, 38.21it/s]\n",
            "(29/29): Propagating: 100%|██████████| 128/128 [00:03<00:00, 37.95it/s]\n",
            "manager stage: Modifiers initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:49:31.337076+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "manager stage: Modifiers finalized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:49:31.339960+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
            "2025-04-20T16:49:31.340423+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking whether model follows 2:4 sparsity structure: 100%|██████████| 197/197 [00:03<00:00, 59.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T16:50:14.095011+0000 | get_model_compressor | INFO - Inferring a sparsity configuration requires a global sparsity calculation. This can be costly for large models. To skip the calculation of compression statistics set skip_compression_stats=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating model sparsity: 100%|██████████| 731/731 [00:02<00:00, 288.73it/s]\n",
            "Checking whether model follows 2:4 sparsity structure: 100%|██████████| 197/197 [00:02<00:00, 70.81it/s]\n",
            "Calculating quantization compression ratio: 284it [00:00, 453.51it/s]\n",
            "Quantized Compression: 100%|██████████| 731/731 [00:10<00:00, 72.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to: /content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/W4A16GPTQwandb/ /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "id": "5S5GBtuhcNsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2314edf3-0c03-4290-b6ef-9c1ff2f6abc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/W4A16GPTQwandb/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/tensorboard/ /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "id": "xKC-SzbWcPZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d92f8b0-2685-49fa-a677-6c582a50b40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/tensorboard/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm_eval==v0.4.3\n",
        "!pip install transformers vllm torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cjbpPwrjcZDR",
        "outputId": "f2159b0f-dd19-478e-cad1-effe1d7ae2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lm_eval==v0.4.3\n",
            "  Downloading lm_eval-0.4.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (1.5.2)\n",
            "Collecting evaluate (from lm_eval==v0.4.3)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (3.5.0)\n",
            "Collecting jsonlines (from lm_eval==v0.4.3)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==v0.4.3)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==v0.4.3)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==v0.4.3)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==v0.4.3)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (1.6.1)\n",
            "Collecting sqlitedict (from lm_eval==v0.4.3)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (2.6.0+cu124)\n",
            "Collecting tqdm-multiprocess (from lm_eval==v0.4.3)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (4.49.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.3.8)\n",
            "Collecting word2number (from lm_eval==v0.4.3)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (10.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm_eval==v0.4.3) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.11.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==v0.4.3)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==v0.4.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (5.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm_eval==v0.4.3) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm_eval==v0.4.3) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm_eval==v0.4.3) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==v0.4.3) (75.2.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.19.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==v0.4.3) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm_eval==v0.4.3) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==v0.4.3) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm_eval==v0.4.3) (2025.2)\n",
            "Downloading lm_eval-0.4.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=97c646c3be83bcde8e2ab005a493de81928a979f6f8fb136c07a435e1e788550\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=ec9d0304264a8b5be616690d57ee6eb3aa9b7b4a0f3b0230b63b29c2f1819cf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=aa6b5a46b124b3b8d85d4463fe21e86b518688a9b41310e7cce8c29899c7bde3\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, tcolorpy, pybind11, portalocker, pathvalidate, mbstrdecoder, jsonlines, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, DataProperty, tabledata, evaluate, pytablewriter, lm_eval\n",
            "Successfully installed DataProperty-1.1.0 colorama-0.4.6 evaluate-0.4.3 jsonlines-4.0.0 lm_eval-0.4.3 mbstrdecoder-1.1.4 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Collecting vllm\n",
            "  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (5.29.4)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.75.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.1.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.9 (from vllm)\n",
            "  Downloading llguidance-0.7.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.18 (from vllm)\n",
            "  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.16.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.3)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.14.1)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
            "  Downloading ray-2.43.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Collecting xformers==0.0.29.post2 (from vllm)\n",
            "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
            "  Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Collecting importlib_metadata (from vllm)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.5.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.19.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.2)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.14.1-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl (294.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.1/294.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.16.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions_ai-0.4.3-py3-none-any.whl (5.4 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.43.0-cp311-cp311-manylinux2014_x86_64.whl (67.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.1-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blake3, uvloop, uvicorn, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, ninja, msgspec, llvmlite, llguidance, lark, interegular, importlib_metadata, httptools, hf-xet, gguf, dnspython, diskcache, astor, airportsdata, watchfiles, tiktoken, starlette, opentelemetry-proto, opentelemetry-api, numba, email-validator, depyf, rich-toolkit, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, lm-format-enforcer, fastapi, xformers, transformers, ray, outlines_core, opentelemetry-sdk, mistral_common, fastapi-cli, xgrammar, outlines, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, vllm\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.32.1\n",
            "    Uninstalling opentelemetry-api-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.32.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.53b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.53b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.53b1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.49.0\n",
            "    Uninstalling transformers-4.49.0:\n",
            "      Successfully uninstalled transformers-4.49.0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.32.1\n",
            "    Uninstalling opentelemetry-sdk-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmcompressor 0.5.0 requires transformers<4.50,>4.0, but you have transformers 4.51.3 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-api>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-api 1.26.0 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-sdk>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-sdk 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250224 astor-0.8.1 blake3-1.0.4 depyf-0.18.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.12 fastapi-cli-0.0.7 gguf-0.16.2 hf-xet-1.0.3 httptools-0.6.4 importlib_metadata-8.0.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.16 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.5.4 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.3 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.6 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 ray-2.43.0 rich-toolkit-0.14.1 starlette-0.46.2 tiktoken-0.9.0 transformers-4.51.3 uvicorn-0.34.2 uvloop-0.21.0 vllm-0.8.4 watchfiles-1.0.5 xformers-0.0.29.post2 xgrammar-0.1.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata",
                  "transformers"
                ]
              },
              "id": "16449041d73346a5bf82968018973dba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "  --model hf \\\n",
        "  --model_args pretrained=\"/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16\",device_map=\"auto\" \\\n",
        "  --tasks mmlu_high_school_computer_science,gsm8k \\\n",
        "  --num_fewshot 5 \\\n",
        "  --batch_size 1 \\\n",
        "  --max_batch_size 1 \\\n",
        "  --limit 250\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6RAGdSrn-cK",
        "outputId": "5fac8101-d483-40ad-dd4d-cae61186e7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20 17:01:01.865419: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-20 17:01:01.882926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745168461.904582    7421 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745168461.911071    7421 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-20 17:01:01.932737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 04-20 17:01:05 [__init__.py:239] Automatically detected platform cuda.\n",
            "2025-04-20:17:01:07,782 INFO     [__main__.py:272] Verbosity set to INFO\n",
            "2025-04-20:17:01:12,747 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
            "2025-04-20:17:01:12,748 INFO     [__main__.py:369] Selected Tasks: ['gsm8k', 'mmlu_high_school_computer_science']\n",
            "2025-04-20:17:01:12,752 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2025-04-20:17:01:12,752 INFO     [evaluator.py:189] Initializing hf model, with arguments: {'pretrained': '/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16', 'device_map': 'auto'}\n",
            "2025-04-20:17:01:12,787 INFO     [huggingface.py:170] Using device 'cuda'\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "2025-04-20:17:01:13,571 INFO     [modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "README.md: 100% 7.94k/7.94k [00:00<00:00, 48.3MB/s]\n",
            "train-00000-of-00001.parquet: 100% 2.31M/2.31M [00:00<00:00, 25.9MB/s]\n",
            "test-00000-of-00001.parquet: 100% 419k/419k [00:00<00:00, 107MB/s]\n",
            "Generating train split: 100% 7473/7473 [00:00<00:00, 228845.36 examples/s]\n",
            "Generating test split: 100% 1319/1319 [00:00<00:00, 320155.50 examples/s]\n",
            "README.md: 100% 1.11k/1.11k [00:00<00:00, 8.94MB/s]\n",
            "mmlu_no_train.py: 100% 5.86k/5.86k [00:00<00:00, 46.4MB/s]\n",
            "data.tar: 100% 166M/166M [00:00<00:00, 171MB/s]\n",
            "Generating test split: 100 examples [00:00, 1326.62 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3369.52 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.06 examples/s]\n",
            "2025-04-20:17:01:21,792 WARNING  [evaluator.py:251] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
            "2025-04-20:17:01:21,792 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
            "2025-04-20:17:01:21,792 WARNING  [evaluator.py:251] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
            "2025-04-20:17:01:21,792 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
            "2025-04-20:17:01:21,793 INFO     [task.py:411] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 141.75it/s]\n",
            "2025-04-20:17:01:22,504 INFO     [task.py:411] Building contexts for gsm8k on rank 0...\n",
            "100% 250/250 [00:01<00:00, 245.54it/s]\n",
            "2025-04-20:17:01:23,528 INFO     [evaluator.py:438] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 400/400 [01:24<00:00,  4.72it/s]\n",
            "2025-04-20:17:02:50,188 INFO     [evaluator.py:438] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Running generate_until requests: 100% 250/250 [6:40:00<00:00, 96.00s/it]\n",
            "2025-04-20:23:42:50,981 WARNING  [huggingface.py:1315] Failed to get model SHA for /content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-04-20:23:42:53,483 INFO     [evaluation_tracker.py:240] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w4a16,device_map=auto), gen_kwargs: (None), limit: 250.0, num_fewshot: 5, batch_size: 1\n",
            "|           Tasks            |Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
            "|----------------------------|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
            "|gsm8k                       |      3|flexible-extract|     5|exact_match|↑  |0.632|±  |0.0306|\n",
            "|                            |       |strict-match    |     5|exact_match|↑  |0.592|±  |0.0311|\n",
            "|high_school_computer_science|      0|none            |     5|acc        |↑  |0.410|±  |0.0494|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}