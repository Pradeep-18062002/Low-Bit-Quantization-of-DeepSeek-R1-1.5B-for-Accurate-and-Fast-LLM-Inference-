{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f074a73e86b844b988f1675385a22dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa96cc0bc9bf4ced99ba2969137ccc0a",
              "IPY_MODEL_79d6c7d08f664ff4af84fa97e71da2db",
              "IPY_MODEL_0d88ac16aa5445e7b16e93eb7b62705a"
            ],
            "layout": "IPY_MODEL_40736ccd41834d37b5926f0e7ffbb058"
          }
        },
        "fa96cc0bc9bf4ced99ba2969137ccc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1ca2f1c65b484998cf8a6eb0357849",
            "placeholder": "​",
            "style": "IPY_MODEL_dcfe9dee9e7645bfbf5933fdd8810703",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "79d6c7d08f664ff4af84fa97e71da2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eae62dc787d4bb2a1a3c89c29ce3e82",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7cfc1191ec94f00993da9bcf96c2820",
            "value": 3071
          }
        },
        "0d88ac16aa5445e7b16e93eb7b62705a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59abe2f97bdf4b7aa8b24fd09ca3610a",
            "placeholder": "​",
            "style": "IPY_MODEL_4c5cbc09dca046d7bc7b912e18701c79",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 361kB/s]"
          }
        },
        "40736ccd41834d37b5926f0e7ffbb058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1ca2f1c65b484998cf8a6eb0357849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfe9dee9e7645bfbf5933fdd8810703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eae62dc787d4bb2a1a3c89c29ce3e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7cfc1191ec94f00993da9bcf96c2820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59abe2f97bdf4b7aa8b24fd09ca3610a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5cbc09dca046d7bc7b912e18701c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "062124b02a344f72b9fcfe7544800f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acff315da7344532bdbc39cf8ecddb1d",
              "IPY_MODEL_02754f9005d2453982ddefa0fcc6586e",
              "IPY_MODEL_ef948964c68b4aa493889c7e8d995081"
            ],
            "layout": "IPY_MODEL_4a24e0eb77f24a5babc2a02648945b31"
          }
        },
        "acff315da7344532bdbc39cf8ecddb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63d89ddd10a41149d3247ecb8864f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_bc45ed0bb7ae41bf86f83e47522e6de2",
            "value": "tokenizer.json: 100%"
          }
        },
        "02754f9005d2453982ddefa0fcc6586e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee13709ce58d4322afe95f161cdf0812",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8d6cca4a308458d8066d0af84d917fd",
            "value": 7031660
          }
        },
        "ef948964c68b4aa493889c7e8d995081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55091bc591441b7a789c259f2842c55",
            "placeholder": "​",
            "style": "IPY_MODEL_da952633b8e245eca6853654fa8dfffb",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 26.0MB/s]"
          }
        },
        "4a24e0eb77f24a5babc2a02648945b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63d89ddd10a41149d3247ecb8864f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc45ed0bb7ae41bf86f83e47522e6de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee13709ce58d4322afe95f161cdf0812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d6cca4a308458d8066d0af84d917fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f55091bc591441b7a789c259f2842c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da952633b8e245eca6853654fa8dfffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6f41b894d7544daae4f05a3e35e669c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd4ba9aa5ce748f8846437b1259b3186",
              "IPY_MODEL_84cec2b686ee4e40bac4b592d4fdee72",
              "IPY_MODEL_2b105a094abd488596b2cbab66bf6366"
            ],
            "layout": "IPY_MODEL_da329b80b79c48ab93caedbf91753031"
          }
        },
        "dd4ba9aa5ce748f8846437b1259b3186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda6aa65b5c84379974b5e3b035e05e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0a199c7190ab4c92b2de3d20297d51a2",
            "value": "config.json: 100%"
          }
        },
        "84cec2b686ee4e40bac4b592d4fdee72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f9244a987b49c49f16284d816d75a2",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fe3dab0aac45ee910961f81cd1a056",
            "value": 679
          }
        },
        "2b105a094abd488596b2cbab66bf6366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33cc6e6e7da43bc81e53f253f536d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_d6475a35b55c4fdb8909e574d71b005a",
            "value": " 679/679 [00:00&lt;00:00, 94.1kB/s]"
          }
        },
        "da329b80b79c48ab93caedbf91753031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda6aa65b5c84379974b5e3b035e05e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a199c7190ab4c92b2de3d20297d51a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f9244a987b49c49f16284d816d75a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fe3dab0aac45ee910961f81cd1a056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b33cc6e6e7da43bc81e53f253f536d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6475a35b55c4fdb8909e574d71b005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aef62fd5fd3c4ff797158fbc50c7b1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f760bb1d93a4b5a8af97b46cc5252bc",
              "IPY_MODEL_52e85af4aa6e46f8b78f66633043fd0c",
              "IPY_MODEL_79dcea8676fd45cf9b8757dfdbb9c65d"
            ],
            "layout": "IPY_MODEL_c3ec84abd11f47708366b552c05d6148"
          }
        },
        "5f760bb1d93a4b5a8af97b46cc5252bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a895a7a8a6854c8295bc5243235ef8c8",
            "placeholder": "​",
            "style": "IPY_MODEL_887ab2e0aecf45bf925fa3011591a4cd",
            "value": "model.safetensors: 100%"
          }
        },
        "52e85af4aa6e46f8b78f66633043fd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b025896260f4b9fa08ee8a2fe0942c6",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_971c48b5a06c4b22a14f30f46d130a44",
            "value": 3554214621
          }
        },
        "79dcea8676fd45cf9b8757dfdbb9c65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051de9d1fdef43c09a41f026d75d5685",
            "placeholder": "​",
            "style": "IPY_MODEL_453fe161c287459c8719985b2ef4a9cb",
            "value": " 3.55G/3.55G [00:15&lt;00:00, 250MB/s]"
          }
        },
        "c3ec84abd11f47708366b552c05d6148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a895a7a8a6854c8295bc5243235ef8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887ab2e0aecf45bf925fa3011591a4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b025896260f4b9fa08ee8a2fe0942c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971c48b5a06c4b22a14f30f46d130a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "051de9d1fdef43c09a41f026d75d5685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453fe161c287459c8719985b2ef4a9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "340e1ce11528477d9161346e41d16143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04095ea891564ec59e132790b171337b",
              "IPY_MODEL_e126e495a77c4e38863bdd2752e3dfa6",
              "IPY_MODEL_f703c02e4cf546399d8e94bb0a9300d1"
            ],
            "layout": "IPY_MODEL_624bfc45efad4637b45230c01e1a5056"
          }
        },
        "04095ea891564ec59e132790b171337b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd1a4e489e64f4ba1e57abec76d211c",
            "placeholder": "​",
            "style": "IPY_MODEL_2d3793fdd405457598b15e854303dcf9",
            "value": "generation_config.json: 100%"
          }
        },
        "e126e495a77c4e38863bdd2752e3dfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ece71ad0b44f2eab13ddeee9103503",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0161e5e03469487eb75691bf5f4e2230",
            "value": 181
          }
        },
        "f703c02e4cf546399d8e94bb0a9300d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cdbf92d21b947b4b118b29af43eb757",
            "placeholder": "​",
            "style": "IPY_MODEL_bef7ad89cd0b4df09b955de9501595e2",
            "value": " 181/181 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "624bfc45efad4637b45230c01e1a5056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd1a4e489e64f4ba1e57abec76d211c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3793fdd405457598b15e854303dcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ece71ad0b44f2eab13ddeee9103503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0161e5e03469487eb75691bf5f4e2230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cdbf92d21b947b4b118b29af43eb757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef7ad89cd0b4df09b955de9501595e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4338dd0de20a4193a57bac539716f7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6fab75aa1b74f0aa00ef71cc86eadd9",
              "IPY_MODEL_936c040901bd4eaeb72fd1fe689eaf15",
              "IPY_MODEL_5a3ea6757d754d8889060b0acceae767"
            ],
            "layout": "IPY_MODEL_9a6eccb9be0544e9a310c25df503bd33"
          }
        },
        "e6fab75aa1b74f0aa00ef71cc86eadd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ed44fc2d7542f7b54dc52bb9a839e3",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8d2ed1a5bc4c32abe6394f95c39c10",
            "value": "README.md: 100%"
          }
        },
        "936c040901bd4eaeb72fd1fe689eaf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e23bbe68344bf89ff9c29ae0072c37",
            "max": 832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb479ff58f4a49f9a376fc7489358958",
            "value": 832
          }
        },
        "5a3ea6757d754d8889060b0acceae767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0edba2db659401e8535f2c1e02c4ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_8247593a85124a10b1b72526807f064d",
            "value": " 832/832 [00:00&lt;00:00, 97.9kB/s]"
          }
        },
        "9a6eccb9be0544e9a310c25df503bd33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ed44fc2d7542f7b54dc52bb9a839e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8d2ed1a5bc4c32abe6394f95c39c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e23bbe68344bf89ff9c29ae0072c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb479ff58f4a49f9a376fc7489358958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0edba2db659401e8535f2c1e02c4ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8247593a85124a10b1b72526807f064d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51ed4d81afb4ad7826f90c64a7f5f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c44fe73ae9824dcaa7c0f27104d3f1fc",
              "IPY_MODEL_feb62444d62b40dda3b21576d1cab416",
              "IPY_MODEL_fd9b63482a544a1cbfba7942e85d8770"
            ],
            "layout": "IPY_MODEL_c82f256c73b24337a7d07bcb4f0f4e7e"
          }
        },
        "c44fe73ae9824dcaa7c0f27104d3f1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f58211d607c4f12b39ba21c7aed0ce4",
            "placeholder": "​",
            "style": "IPY_MODEL_18658099529244d6b5eba1058082fb62",
            "value": "calibration.json.gz: 100%"
          }
        },
        "feb62444d62b40dda3b21576d1cab416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9048a60fc41498cbeba90668bbc270d",
            "max": 4575521,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f911d49c3ad4362a92c3426545a2f32",
            "value": 4575521
          }
        },
        "fd9b63482a544a1cbfba7942e85d8770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce71996c000469ab7bc4e14a8a96acf",
            "placeholder": "​",
            "style": "IPY_MODEL_fc34d4cb69ed4991a94ce4870e25d8c0",
            "value": " 4.58M/4.58M [00:00&lt;00:00, 39.9MB/s]"
          }
        },
        "c82f256c73b24337a7d07bcb4f0f4e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f58211d607c4f12b39ba21c7aed0ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18658099529244d6b5eba1058082fb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9048a60fc41498cbeba90668bbc270d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f911d49c3ad4362a92c3426545a2f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ce71996c000469ab7bc4e14a8a96acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc34d4cb69ed4991a94ce4870e25d8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc6c705f4664ad6a500edbff4f5df20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_183b3342ab2349b09b8bab12d929b619",
              "IPY_MODEL_b5f3e46fe7d6475eb9299c793909404b",
              "IPY_MODEL_e97b2cb3015841928f9772fe391ac187"
            ],
            "layout": "IPY_MODEL_e59404b99af2424a8b751b1651736a7b"
          }
        },
        "183b3342ab2349b09b8bab12d929b619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f1d4dc498fa4c63a4914d2425d6050d",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b3a16e2b484e4cb7438eb4b9ee80f6",
            "value": "Generating train split: 100%"
          }
        },
        "b5f3e46fe7d6475eb9299c793909404b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490b38457fc1463ea3027ff6b19bf516",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f9c8298d28c430988abf83c21e70362",
            "value": 10000
          }
        },
        "e97b2cb3015841928f9772fe391ac187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b639589ba874ccfbe52c4c85ac9c820",
            "placeholder": "​",
            "style": "IPY_MODEL_18afdf2d0e164397a8bb8dabdf403cf7",
            "value": " 10000/10000 [00:00&lt;00:00, 39930.54 examples/s]"
          }
        },
        "e59404b99af2424a8b751b1651736a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1d4dc498fa4c63a4914d2425d6050d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b3a16e2b484e4cb7438eb4b9ee80f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "490b38457fc1463ea3027ff6b19bf516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9c8298d28c430988abf83c21e70362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b639589ba874ccfbe52c4c85ac9c820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18afdf2d0e164397a8bb8dabdf403cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51ed6d96bb741709365a2df18cffce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d27128eb6e9e4c69a0a0336294096fea",
              "IPY_MODEL_ee290e6b63d74c8db7cf8db174c1e317",
              "IPY_MODEL_eb4ec9100c4c46a989e15417bde3f094"
            ],
            "layout": "IPY_MODEL_0decfe5fdc8343eda06d37c6b5c17c43"
          }
        },
        "d27128eb6e9e4c69a0a0336294096fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09010baa62a4ea8b12c99c131164232",
            "placeholder": "​",
            "style": "IPY_MODEL_78dc89eabfe245b8a289c0b2ab0eba4e",
            "value": "Map: 100%"
          }
        },
        "ee290e6b63d74c8db7cf8db174c1e317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce52e458b1f420aab48df8c5628b76c",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad91444ccb724d9281d7148a1aac4e5a",
            "value": 10000
          }
        },
        "eb4ec9100c4c46a989e15417bde3f094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38374b6b1ffd43c582ee49d530106c62",
            "placeholder": "​",
            "style": "IPY_MODEL_ae5c9cad35074c61914bcf7c2cf51820",
            "value": " 10000/10000 [00:01&lt;00:00, 5927.85 examples/s]"
          }
        },
        "0decfe5fdc8343eda06d37c6b5c17c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09010baa62a4ea8b12c99c131164232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78dc89eabfe245b8a289c0b2ab0eba4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce52e458b1f420aab48df8c5628b76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad91444ccb724d9281d7148a1aac4e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38374b6b1ffd43c582ee49d530106c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5c9cad35074c61914bcf7c2cf51820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36f43bd3381b4fddb0f789fca7ee05c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0e8c64e9cb248d0b3d60fd95bf6e810",
              "IPY_MODEL_5ae501a35851423ba81bca81dc14968f",
              "IPY_MODEL_1147932b8425435890894110c0ada74f"
            ],
            "layout": "IPY_MODEL_3ecd329f4b2845eea49bfc3f51fc676b"
          }
        },
        "b0e8c64e9cb248d0b3d60fd95bf6e810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296a481705ec4ee0a963d89319d803f9",
            "placeholder": "​",
            "style": "IPY_MODEL_b93533cb2b5d4e57ab030e21de5cfa59",
            "value": "Tokenizing: 100%"
          }
        },
        "5ae501a35851423ba81bca81dc14968f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f90d36b9c72f40a88e94f1cc311ff201",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f582701cb03045e597b08e55e97c0380",
            "value": 10000
          }
        },
        "1147932b8425435890894110c0ada74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b61b4e868f04130b979822920c5b38f",
            "placeholder": "​",
            "style": "IPY_MODEL_00b35412dd69496ab01bf706b67ffb49",
            "value": " 10000/10000 [00:15&lt;00:00, 758.79 examples/s]"
          }
        },
        "3ecd329f4b2845eea49bfc3f51fc676b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296a481705ec4ee0a963d89319d803f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b93533cb2b5d4e57ab030e21de5cfa59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f90d36b9c72f40a88e94f1cc311ff201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f582701cb03045e597b08e55e97c0380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b61b4e868f04130b979822920c5b38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b35412dd69496ab01bf706b67ffb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc8pkJe50w2R",
        "outputId": "646ca454-b9cf-4e2f-8add-412ce7b4c977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llmcompressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58r7Ek5H4qyI",
        "outputId": "42a38129-08ed-495a-bdf6-fa3fe1f72cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llmcompressor\n",
            "  Downloading llmcompressor-0.5.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting loguru (from llmcompressor)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (6.0.2)\n",
            "Collecting numpy<2.0,>=1.17.0 (from llmcompressor)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (2.6.0+cu124)\n",
            "Collecting transformers<4.50,>4.0 (from llmcompressor)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from llmcompressor)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate!=1.1.0,>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (1.5.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (12.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from llmcompressor) (11.1.0)\n",
            "Collecting compressed-tensors==0.9.3 (from llmcompressor)\n",
            "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from compressed-tensors==0.9.3->llmcompressor) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->llmcompressor) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->llmcompressor) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->llmcompressor) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>4.0->llmcompressor) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>4.0->llmcompressor) (0.21.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->llmcompressor)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (2.2.2)\n",
            "Collecting xxhash (from datasets->llmcompressor)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->llmcompressor)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.7.0->llmcompressor)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->llmcompressor) (3.11.15)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->llmcompressor) (12.570.86)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->llmcompressor) (1.19.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->compressed-tensors==0.9.3->llmcompressor) (0.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->llmcompressor) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->llmcompressor) (1.17.0)\n",
            "Downloading llmcompressor-0.5.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.9/245.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, loguru, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, compressed-tensors, llmcompressor\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed compressed-tensors-0.9.3 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 llmcompressor-0.5.0 loguru-0.7.3 multiprocess-0.70.16 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.49.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==2.2.3\n",
        "\n",
        "!pip install peft==0.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lgtclsV4-qi",
        "outputId": "7be0023c-41ab-4972-ec13-bb8ddaab2aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==2.2.3\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmcompressor 0.5.0 requires numpy<2.0,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.3\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.49.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.14.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.14.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.14.0) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.14.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd  /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1HOUNdo5BDw",
        "outputId": "e605eb50-a5ad-4e06-abe4-52b3cb66c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1TMMdJa5E9r",
        "outputId": "b155e196-9e37-4717-daa0-33da052b01b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.2.3\n",
            "Uninstalling numpy-2.2.3:\n",
            "  Successfully uninstalled numpy-2.2.3\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ2dmzrg5gUm",
        "outputId": "50b3da26-08a6-4835-8ebd-05ee8ec47106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "from llmcompressor.modifiers.quantization import QuantizationModifier\n",
        "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
        "from llmcompressor.transformers import oneshot\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "KIqsHzG15mfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model_stub = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "model_name = model_stub.split(\"/\")[-1]\n",
        "\n",
        "num_samples = 128\n",
        "max_seq_len = 1024\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_stub)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_stub,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "f074a73e86b844b988f1675385a22dcc",
            "fa96cc0bc9bf4ced99ba2969137ccc0a",
            "79d6c7d08f664ff4af84fa97e71da2db",
            "0d88ac16aa5445e7b16e93eb7b62705a",
            "40736ccd41834d37b5926f0e7ffbb058",
            "eb1ca2f1c65b484998cf8a6eb0357849",
            "dcfe9dee9e7645bfbf5933fdd8810703",
            "4eae62dc787d4bb2a1a3c89c29ce3e82",
            "a7cfc1191ec94f00993da9bcf96c2820",
            "59abe2f97bdf4b7aa8b24fd09ca3610a",
            "4c5cbc09dca046d7bc7b912e18701c79",
            "062124b02a344f72b9fcfe7544800f69",
            "acff315da7344532bdbc39cf8ecddb1d",
            "02754f9005d2453982ddefa0fcc6586e",
            "ef948964c68b4aa493889c7e8d995081",
            "4a24e0eb77f24a5babc2a02648945b31",
            "f63d89ddd10a41149d3247ecb8864f0d",
            "bc45ed0bb7ae41bf86f83e47522e6de2",
            "ee13709ce58d4322afe95f161cdf0812",
            "f8d6cca4a308458d8066d0af84d917fd",
            "f55091bc591441b7a789c259f2842c55",
            "da952633b8e245eca6853654fa8dfffb",
            "f6f41b894d7544daae4f05a3e35e669c",
            "dd4ba9aa5ce748f8846437b1259b3186",
            "84cec2b686ee4e40bac4b592d4fdee72",
            "2b105a094abd488596b2cbab66bf6366",
            "da329b80b79c48ab93caedbf91753031",
            "fda6aa65b5c84379974b5e3b035e05e6",
            "0a199c7190ab4c92b2de3d20297d51a2",
            "96f9244a987b49c49f16284d816d75a2",
            "52fe3dab0aac45ee910961f81cd1a056",
            "b33cc6e6e7da43bc81e53f253f536d9e",
            "d6475a35b55c4fdb8909e574d71b005a",
            "aef62fd5fd3c4ff797158fbc50c7b1db",
            "5f760bb1d93a4b5a8af97b46cc5252bc",
            "52e85af4aa6e46f8b78f66633043fd0c",
            "79dcea8676fd45cf9b8757dfdbb9c65d",
            "c3ec84abd11f47708366b552c05d6148",
            "a895a7a8a6854c8295bc5243235ef8c8",
            "887ab2e0aecf45bf925fa3011591a4cd",
            "0b025896260f4b9fa08ee8a2fe0942c6",
            "971c48b5a06c4b22a14f30f46d130a44",
            "051de9d1fdef43c09a41f026d75d5685",
            "453fe161c287459c8719985b2ef4a9cb",
            "340e1ce11528477d9161346e41d16143",
            "04095ea891564ec59e132790b171337b",
            "e126e495a77c4e38863bdd2752e3dfa6",
            "f703c02e4cf546399d8e94bb0a9300d1",
            "624bfc45efad4637b45230c01e1a5056",
            "9bd1a4e489e64f4ba1e57abec76d211c",
            "2d3793fdd405457598b15e854303dcf9",
            "35ece71ad0b44f2eab13ddeee9103503",
            "0161e5e03469487eb75691bf5f4e2230",
            "3cdbf92d21b947b4b118b29af43eb757",
            "bef7ad89cd0b4df09b955de9501595e2"
          ]
        },
        "id": "00qcdHrj5pX0",
        "outputId": "c3c5e8d1-0132-4fbd-ee82-4a4b493d4739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f074a73e86b844b988f1675385a22dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062124b02a344f72b9fcfe7544800f69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6f41b894d7544daae4f05a3e35e669c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aef62fd5fd3c4ff797158fbc50c7b1db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "340e1ce11528477d9161346e41d16143"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.base_model.layers[0].mlp.gate_proj.weight.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6A59X0P5sxy",
        "outputId": "02cef9db-a798-4978-bbf5-ffb1c255b913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_fn(example):\n",
        "  return {\"text\": tokenizer.apply_chat_template(\n",
        "      example[\"messages\"],\n",
        "      add_generation_prompt=False,\n",
        "      tokenize=False\n",
        "  )}\n",
        "ds = load_dataset(\"neuralmagic/LLM_compression_calibration\", split=\"train\")\n",
        "ds = ds.map(preprocess_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "4338dd0de20a4193a57bac539716f7a7",
            "e6fab75aa1b74f0aa00ef71cc86eadd9",
            "936c040901bd4eaeb72fd1fe689eaf15",
            "5a3ea6757d754d8889060b0acceae767",
            "9a6eccb9be0544e9a310c25df503bd33",
            "e1ed44fc2d7542f7b54dc52bb9a839e3",
            "aa8d2ed1a5bc4c32abe6394f95c39c10",
            "21e23bbe68344bf89ff9c29ae0072c37",
            "cb479ff58f4a49f9a376fc7489358958",
            "d0edba2db659401e8535f2c1e02c4ea9",
            "8247593a85124a10b1b72526807f064d",
            "b51ed4d81afb4ad7826f90c64a7f5f49",
            "c44fe73ae9824dcaa7c0f27104d3f1fc",
            "feb62444d62b40dda3b21576d1cab416",
            "fd9b63482a544a1cbfba7942e85d8770",
            "c82f256c73b24337a7d07bcb4f0f4e7e",
            "1f58211d607c4f12b39ba21c7aed0ce4",
            "18658099529244d6b5eba1058082fb62",
            "a9048a60fc41498cbeba90668bbc270d",
            "2f911d49c3ad4362a92c3426545a2f32",
            "5ce71996c000469ab7bc4e14a8a96acf",
            "fc34d4cb69ed4991a94ce4870e25d8c0",
            "adc6c705f4664ad6a500edbff4f5df20",
            "183b3342ab2349b09b8bab12d929b619",
            "b5f3e46fe7d6475eb9299c793909404b",
            "e97b2cb3015841928f9772fe391ac187",
            "e59404b99af2424a8b751b1651736a7b",
            "2f1d4dc498fa4c63a4914d2425d6050d",
            "a5b3a16e2b484e4cb7438eb4b9ee80f6",
            "490b38457fc1463ea3027ff6b19bf516",
            "4f9c8298d28c430988abf83c21e70362",
            "8b639589ba874ccfbe52c4c85ac9c820",
            "18afdf2d0e164397a8bb8dabdf403cf7",
            "d51ed6d96bb741709365a2df18cffce3",
            "d27128eb6e9e4c69a0a0336294096fea",
            "ee290e6b63d74c8db7cf8db174c1e317",
            "eb4ec9100c4c46a989e15417bde3f094",
            "0decfe5fdc8343eda06d37c6b5c17c43",
            "a09010baa62a4ea8b12c99c131164232",
            "78dc89eabfe245b8a289c0b2ab0eba4e",
            "2ce52e458b1f420aab48df8c5628b76c",
            "ad91444ccb724d9281d7148a1aac4e5a",
            "38374b6b1ffd43c582ee49d530106c62",
            "ae5c9cad35074c61914bcf7c2cf51820"
          ]
        },
        "id": "42EnEuiO5zc7",
        "outputId": "b17331a4-0b2f-4055-d0c8-350c78fb2ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/832 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4338dd0de20a4193a57bac539716f7a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "calibration.json.gz:   0%|          | 0.00/4.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b51ed4d81afb4ad7826f90c64a7f5f49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adc6c705f4664ad6a500edbff4f5df20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d51ed6d96bb741709365a2df18cffce3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QuantizationModifier(\n",
        "    targets=\"Linear\",\n",
        "    scheme=\"W8A8\",\n",
        "    ignore=[\"lm_head\"],\n",
        "    dampening_frac=0.1,\n",
        ")\n",
        "\n",
        "recipe = [\n",
        "    SmoothQuantModifier(smoothing_strength=0.8),\n",
        "    GPTQModifier(targets=\"Linear\", scheme=\"W8A8\", ignore=[\"lm_head\"]),\n",
        "]\n",
        "\n",
        "# Apply quantization.\n",
        "oneshot(\n",
        "    model=model,\n",
        "    dataset=ds,\n",
        "    recipe=recipe,\n",
        "    max_seq_length=max_seq_len,\n",
        "    num_calibration_samples=num_samples,\n",
        ")\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/CS594/\" + model_name + \"-gptqquantized.w8a8\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"Model and tokenizer saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36f43bd3381b4fddb0f789fca7ee05c5",
            "b0e8c64e9cb248d0b3d60fd95bf6e810",
            "5ae501a35851423ba81bca81dc14968f",
            "1147932b8425435890894110c0ada74f",
            "3ecd329f4b2845eea49bfc3f51fc676b",
            "296a481705ec4ee0a963d89319d803f9",
            "b93533cb2b5d4e57ab030e21de5cfa59",
            "f90d36b9c72f40a88e94f1cc311ff201",
            "f582701cb03045e597b08e55e97c0380",
            "5b61b4e868f04130b979822920c5b38f",
            "00b35412dd69496ab01bf706b67ffb49"
          ]
        },
        "id": "Bh6DkXBz53V2",
        "outputId": "0e4c1196-ae5d-4793-a14a-3dc84aea78f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-f1ceb54eaead>:14: DeprecationWarning: `from llmcompressor.transformers import oneshot` is deprecated, please use `from llmcompressor import oneshot`.\n",
            "  oneshot(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36f43bd3381b4fddb0f789fca7ee05c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:18:53.523331+0000 | reset | INFO - Compression lifecycle reset\n",
            "2025-04-20T00:18:53.524745+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-04-20T00:18:53.553079+0000 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n",
            "2025-04-20T00:18:54.367340+0000 | _calibrate | INFO - Running SmoothQuantModifier calibration with 128 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128/128 [00:27<00:00,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:21.854698+0000 | _apply_smoothing | INFO - Smoothing activation scales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:22.113854+0000 | _check_build_quant_modifier | WARNING - GPTQ quantization is set to True without an active quantization modifier.\n",
            "2025-04-20T00:19:22.114724+0000 | _build_quant_modifier | INFO - Building quantization modifier with args: {'targets': 'Linear', 'scheme': 'W8A8', 'ignore': ['lm_head']}\n",
            "2025-04-20T00:19:22.157381+0000 | _check_calibration_data | INFO - Skipping QuantizationModifier calibration, it is not required for the provided quantization config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preparing intermediates cache: 100%|██████████| 128/128 [00:00<00:00, 647.00it/s]\n",
            "(1/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:25.054419+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:26.073972+0000 | compress | METRIC - time 1.02s\n",
            "2025-04-20T00:19:26.074746+0000 | compress | METRIC - error 26.39\n",
            "2025-04-20T00:19:26.076132+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:26.076619+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:19:26.077791+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:19:26.870513+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:19:26.871430+0000 | compress | METRIC - error 1.47\n",
            "2025-04-20T00:19:26.872201+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:26.873307+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:26.874945+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:19:27.670400+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:19:27.671369+0000 | compress | METRIC - error 0.45\n",
            "2025-04-20T00:19:27.672293+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:27.672950+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:27.673944+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:19:28.490916+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:19:28.491851+0000 | compress | METRIC - error 3.66\n",
            "2025-04-20T00:19:28.492656+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:28.493129+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:19:28.494206+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:19:29.363803+0000 | compress | METRIC - time 0.87s\n",
            "2025-04-20T00:19:29.364872+0000 | compress | METRIC - error 7.76\n",
            "2025-04-20T00:19:29.365627+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:29.366211+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:29.367427+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:19:30.201792+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:19:30.202727+0000 | compress | METRIC - error 5.38\n",
            "2025-04-20T00:19:30.203730+0000 | compress | METRIC - GPU 0 | usage: 21.99% | total memory: 42 GB\n",
            "2025-04-20T00:19:30.204324+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:30.205279+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:19:35.082217+0000 | compress | METRIC - time 4.88s\n",
            "2025-04-20T00:19:35.084291+0000 | compress | METRIC - error 2.39\n",
            "2025-04-20T00:19:35.085130+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:35.085701+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(1/29): Propagating: 100%|██████████| 128/128 [00:02<00:00, 56.93it/s]\n",
            "(2/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 44.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:40.196716+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:41.013053+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:19:41.014025+0000 | compress | METRIC - error 4.37\n",
            "2025-04-20T00:19:41.014872+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:41.015363+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:19:41.016253+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:19:41.801277+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:19:41.802238+0000 | compress | METRIC - error 1.25\n",
            "2025-04-20T00:19:41.803012+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:41.803475+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:41.804658+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:19:42.602994+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:19:42.603978+0000 | compress | METRIC - error 0.22\n",
            "2025-04-20T00:19:42.604708+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:42.605335+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:42.606500+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:19:43.405656+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:19:43.406670+0000 | compress | METRIC - error 0.85\n",
            "2025-04-20T00:19:43.407659+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:43.408257+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:19:43.409306+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:19:44.262898+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:19:44.263850+0000 | compress | METRIC - error 430.07\n",
            "2025-04-20T00:19:44.264607+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:44.265206+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:44.266331+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:19:45.086673+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:19:45.087606+0000 | compress | METRIC - error 110.77\n",
            "2025-04-20T00:19:45.088353+0000 | compress | METRIC - GPU 0 | usage: 22.74% | total memory: 42 GB\n",
            "2025-04-20T00:19:45.088878+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:45.090008+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:19:49.944934+0000 | compress | METRIC - time 4.85s\n",
            "2025-04-20T00:19:49.947088+0000 | compress | METRIC - error 385.16\n",
            "2025-04-20T00:19:49.947851+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:49.948486+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(2/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 80.88it/s]\n",
            "(3/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:54.256425+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:19:55.103315+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:19:55.104319+0000 | compress | METRIC - error 11.85\n",
            "2025-04-20T00:19:55.105193+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:55.105748+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:19:55.106760+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:19:55.902223+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:19:55.902992+0000 | compress | METRIC - error 2.61\n",
            "2025-04-20T00:19:55.903963+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:55.904585+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:55.905710+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:19:56.709874+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:19:56.710846+0000 | compress | METRIC - error 0.59\n",
            "2025-04-20T00:19:56.711758+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:56.712340+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:19:56.713593+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:19:57.512872+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:19:57.513834+0000 | compress | METRIC - error 0.67\n",
            "2025-04-20T00:19:57.514718+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:57.515325+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:19:57.516725+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:19:58.386861+0000 | compress | METRIC - time 0.87s\n",
            "2025-04-20T00:19:58.387810+0000 | compress | METRIC - error 682.58\n",
            "2025-04-20T00:19:58.388520+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:58.389126+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:58.390210+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:19:59.247906+0000 | compress | METRIC - time 0.86s\n",
            "2025-04-20T00:19:59.248875+0000 | compress | METRIC - error 95.28\n",
            "2025-04-20T00:19:59.249589+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:19:59.250074+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:19:59.250963+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:20:04.059213+0000 | compress | METRIC - time 4.81s\n",
            "2025-04-20T00:20:04.061324+0000 | compress | METRIC - error 72222.91\n",
            "2025-04-20T00:20:04.062076+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:04.062511+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(3/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.93it/s]\n",
            "(4/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:08.228054+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:09.055443+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:09.056201+0000 | compress | METRIC - error 13.67\n",
            "2025-04-20T00:20:09.057091+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:09.057857+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:20:09.058739+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:20:09.844412+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:20:09.845590+0000 | compress | METRIC - error 3.34\n",
            "2025-04-20T00:20:09.846602+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:09.847152+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:09.848272+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:20:10.651747+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:20:10.652680+0000 | compress | METRIC - error 0.87\n",
            "2025-04-20T00:20:10.653402+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:10.653864+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:10.655012+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:20:11.453399+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:20:11.454588+0000 | compress | METRIC - error 0.12\n",
            "2025-04-20T00:20:11.455175+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:11.455652+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:20:11.456674+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:20:12.276171+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:20:12.277167+0000 | compress | METRIC - error 997.25\n",
            "2025-04-20T00:20:12.278003+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:12.278478+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:12.279457+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:20:13.093539+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:20:13.094510+0000 | compress | METRIC - error 65.92\n",
            "2025-04-20T00:20:13.095176+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:13.095615+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:13.096889+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:20:17.938150+0000 | compress | METRIC - time 4.84s\n",
            "2025-04-20T00:20:17.940265+0000 | compress | METRIC - error 5.06\n",
            "2025-04-20T00:20:17.941165+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:17.941671+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(4/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.51it/s]\n",
            "(5/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:22.116328+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:22.947285+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:22.948076+0000 | compress | METRIC - error 17.12\n",
            "2025-04-20T00:20:22.948952+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:22.949508+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:20:22.950793+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:20:23.749584+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:20:23.750575+0000 | compress | METRIC - error 4.14\n",
            "2025-04-20T00:20:23.751353+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:23.752050+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:23.753075+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:20:24.539921+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:20:24.540868+0000 | compress | METRIC - error 0.99\n",
            "2025-04-20T00:20:24.541587+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:24.542101+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:24.543165+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:20:25.356930+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:20:25.357929+0000 | compress | METRIC - error 1.93\n",
            "2025-04-20T00:20:25.358820+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:25.359505+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:20:25.360528+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:20:26.174116+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:20:26.175210+0000 | compress | METRIC - error 495.45\n",
            "2025-04-20T00:20:26.175836+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:26.176373+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:26.177342+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:20:27.000303+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:20:27.001419+0000 | compress | METRIC - error 39.08\n",
            "2025-04-20T00:20:27.002087+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:27.002669+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:27.003615+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:20:31.771268+0000 | compress | METRIC - time 4.77s\n",
            "2025-04-20T00:20:31.773391+0000 | compress | METRIC - error 15.54\n",
            "2025-04-20T00:20:31.774254+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:31.774910+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(5/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.77it/s]\n",
            "(6/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:35.943685+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:36.750529+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:20:36.751285+0000 | compress | METRIC - error 20.28\n",
            "2025-04-20T00:20:36.752025+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:36.752508+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:20:36.753479+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:20:37.538232+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:20:37.539191+0000 | compress | METRIC - error 5.03\n",
            "2025-04-20T00:20:37.540085+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:37.540707+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:37.541905+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:20:38.373993+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:38.375025+0000 | compress | METRIC - error 1.92\n",
            "2025-04-20T00:20:38.375838+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:38.376451+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:38.377544+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:20:39.205612+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:39.206594+0000 | compress | METRIC - error 1.31\n",
            "2025-04-20T00:20:39.207461+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:39.208269+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:20:39.209329+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:20:40.033355+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:20:40.034411+0000 | compress | METRIC - error 1439.25\n",
            "2025-04-20T00:20:40.035151+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:40.035783+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:40.036884+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:20:40.887953+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:20:40.888898+0000 | compress | METRIC - error 121.57\n",
            "2025-04-20T00:20:40.889728+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:40.890316+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:40.891415+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:20:45.663901+0000 | compress | METRIC - time 4.77s\n",
            "2025-04-20T00:20:45.666121+0000 | compress | METRIC - error 8.87\n",
            "2025-04-20T00:20:45.667149+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:45.667816+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(6/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.71it/s]\n",
            "(7/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:49.837615+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:20:50.638810+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:20:50.639790+0000 | compress | METRIC - error 27.76\n",
            "2025-04-20T00:20:50.640538+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:50.641269+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:20:50.642309+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:20:51.431375+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:20:51.432332+0000 | compress | METRIC - error 6.13\n",
            "2025-04-20T00:20:51.433115+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:51.433645+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:51.434686+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:20:52.249673+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:20:52.250664+0000 | compress | METRIC - error 1.52\n",
            "2025-04-20T00:20:52.251490+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:52.252125+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:20:52.253193+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:20:53.057364+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:20:53.058338+0000 | compress | METRIC - error 1.17\n",
            "2025-04-20T00:20:53.059241+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:53.059801+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:20:53.060857+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:20:53.887480+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:53.888481+0000 | compress | METRIC - error 126.90\n",
            "2025-04-20T00:20:53.889097+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:53.889533+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:53.890715+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:20:54.723442+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:20:54.724372+0000 | compress | METRIC - error 38.94\n",
            "2025-04-20T00:20:54.725289+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:54.725897+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:20:54.727046+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:20:59.551518+0000 | compress | METRIC - time 4.82s\n",
            "2025-04-20T00:20:59.553581+0000 | compress | METRIC - error 12.07\n",
            "2025-04-20T00:20:59.554440+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:20:59.555086+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(7/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.53it/s]\n",
            "(8/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:03.721045+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:04.532803+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:21:04.533541+0000 | compress | METRIC - error 15.22\n",
            "2025-04-20T00:21:04.534216+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:04.534706+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:21:04.535707+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:21:05.326105+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:21:05.327121+0000 | compress | METRIC - error 3.64\n",
            "2025-04-20T00:21:05.327623+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:05.328127+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:05.329322+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:21:06.139395+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:21:06.140478+0000 | compress | METRIC - error 1.45\n",
            "2025-04-20T00:21:06.141118+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:06.141665+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:06.142771+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:21:06.959504+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:06.960456+0000 | compress | METRIC - error 3.78\n",
            "2025-04-20T00:21:06.961195+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:06.961843+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:21:06.962739+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:21:07.786607+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:07.787554+0000 | compress | METRIC - error 89.11\n",
            "2025-04-20T00:21:07.788522+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:07.789095+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:07.790147+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:21:08.654475+0000 | compress | METRIC - time 0.86s\n",
            "2025-04-20T00:21:08.655405+0000 | compress | METRIC - error 44.34\n",
            "2025-04-20T00:21:08.656002+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:08.656544+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:08.658266+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:21:13.464265+0000 | compress | METRIC - time 4.81s\n",
            "2025-04-20T00:21:13.466392+0000 | compress | METRIC - error 16.96\n",
            "2025-04-20T00:21:13.467209+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:13.467894+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(8/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.27it/s]\n",
            "(9/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:17.625289+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:18.448016+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:18.448958+0000 | compress | METRIC - error 40.55\n",
            "2025-04-20T00:21:18.449695+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:18.450141+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:21:18.450960+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:21:19.248354+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:21:19.249365+0000 | compress | METRIC - error 8.53\n",
            "2025-04-20T00:21:19.250184+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:19.250662+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:19.251993+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:21:20.053345+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:21:20.054295+0000 | compress | METRIC - error 1.49\n",
            "2025-04-20T00:21:20.055101+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:20.055693+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:20.056676+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:21:20.866678+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:21:20.867761+0000 | compress | METRIC - error 3.37\n",
            "2025-04-20T00:21:20.868487+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:20.869101+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:21:20.870150+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:21:21.703590+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:21:21.704538+0000 | compress | METRIC - error 97.25\n",
            "2025-04-20T00:21:21.705371+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:21.705904+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:21.706928+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:21:22.533053+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:21:22.534236+0000 | compress | METRIC - error 48.05\n",
            "2025-04-20T00:21:22.534962+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:22.535663+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:22.536500+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:21:27.308560+0000 | compress | METRIC - time 4.77s\n",
            "2025-04-20T00:21:27.310087+0000 | compress | METRIC - error 16.83\n",
            "2025-04-20T00:21:27.310895+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:27.311364+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(9/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.84it/s]\n",
            "(10/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:31.473449+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:32.302784+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:21:32.303795+0000 | compress | METRIC - error 26.08\n",
            "2025-04-20T00:21:32.304578+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:32.305226+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:21:32.306387+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:21:33.098430+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:21:33.099436+0000 | compress | METRIC - error 5.35\n",
            "2025-04-20T00:21:33.099989+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:33.100635+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:33.101802+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:21:33.889312+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:21:33.890354+0000 | compress | METRIC - error 1.43\n",
            "2025-04-20T00:21:33.891412+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:33.891935+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:33.893059+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:21:34.682318+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:21:34.683302+0000 | compress | METRIC - error 5.74\n",
            "2025-04-20T00:21:34.684091+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:34.684647+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:21:34.685731+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:21:35.503297+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:35.504249+0000 | compress | METRIC - error 80.12\n",
            "2025-04-20T00:21:35.505068+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:35.505778+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:35.506861+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:21:36.357714+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:21:36.358829+0000 | compress | METRIC - error 49.68\n",
            "2025-04-20T00:21:36.359587+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:36.360187+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:36.361326+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:21:41.154354+0000 | compress | METRIC - time 4.79s\n",
            "2025-04-20T00:21:41.156507+0000 | compress | METRIC - error 14.87\n",
            "2025-04-20T00:21:41.157289+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:41.158156+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(10/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.27it/s]\n",
            "(11/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:45.314163+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:46.133303+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:46.134216+0000 | compress | METRIC - error 38.21\n",
            "2025-04-20T00:21:46.135125+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:46.135751+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:21:46.136945+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:21:46.958040+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:46.959040+0000 | compress | METRIC - error 7.88\n",
            "2025-04-20T00:21:46.959759+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:46.960560+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:46.961460+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:21:47.775282+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:21:47.776315+0000 | compress | METRIC - error 2.08\n",
            "2025-04-20T00:21:47.777355+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:47.777971+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:21:47.779093+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:21:48.583761+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:21:48.584607+0000 | compress | METRIC - error 5.37\n",
            "2025-04-20T00:21:48.585461+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:48.586147+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:21:48.587175+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:21:49.414749+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:21:49.415742+0000 | compress | METRIC - error 79.20\n",
            "2025-04-20T00:21:49.416423+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:49.417032+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:49.418068+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:21:50.235450+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:21:50.236475+0000 | compress | METRIC - error 49.70\n",
            "2025-04-20T00:21:50.237485+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:50.237988+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:21:50.239161+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:21:55.053046+0000 | compress | METRIC - time 4.81s\n",
            "2025-04-20T00:21:55.055144+0000 | compress | METRIC - error 14.24\n",
            "2025-04-20T00:21:55.056389+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:21:55.057034+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(11/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.75it/s]\n",
            "(12/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:21:59.223838+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:00.036066+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:22:00.037129+0000 | compress | METRIC - error 30.73\n",
            "2025-04-20T00:22:00.038268+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:00.038875+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:22:00.039987+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:22:00.837050+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:00.838075+0000 | compress | METRIC - error 6.27\n",
            "2025-04-20T00:22:00.839020+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:00.839642+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:00.840907+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:22:01.637476+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:01.638273+0000 | compress | METRIC - error 1.87\n",
            "2025-04-20T00:22:01.639264+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:01.639781+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:01.640864+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:22:02.437189+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:02.438156+0000 | compress | METRIC - error 5.96\n",
            "2025-04-20T00:22:02.439141+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:02.439642+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:22:02.440726+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:22:03.255182+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:22:03.256326+0000 | compress | METRIC - error 97.00\n",
            "2025-04-20T00:22:03.257324+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:03.257876+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:03.258750+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:22:04.075443+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:22:04.076480+0000 | compress | METRIC - error 48.69\n",
            "2025-04-20T00:22:04.077455+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:04.077961+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:04.079116+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:22:08.936772+0000 | compress | METRIC - time 4.86s\n",
            "2025-04-20T00:22:08.938858+0000 | compress | METRIC - error 12.71\n",
            "2025-04-20T00:22:08.939624+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:08.940167+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(12/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.94it/s]\n",
            "(13/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:13.099245+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:13.929799+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:22:13.930516+0000 | compress | METRIC - error 41.45\n",
            "2025-04-20T00:22:13.931260+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:13.931729+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:22:13.932802+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:22:14.734544+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:14.735551+0000 | compress | METRIC - error 8.25\n",
            "2025-04-20T00:22:14.736401+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:14.736955+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:14.737974+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:22:15.539004+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:15.539957+0000 | compress | METRIC - error 2.32\n",
            "2025-04-20T00:22:15.540789+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:15.541546+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:15.542328+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:22:16.338629+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:16.339686+0000 | compress | METRIC - error 3.47\n",
            "2025-04-20T00:22:16.340502+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:16.341038+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:22:16.342227+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:22:17.184025+0000 | compress | METRIC - time 0.84s\n",
            "2025-04-20T00:22:17.184978+0000 | compress | METRIC - error 74.33\n",
            "2025-04-20T00:22:17.185699+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:17.186138+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:17.187073+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:22:18.003367+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:22:18.004200+0000 | compress | METRIC - error 49.42\n",
            "2025-04-20T00:22:18.004945+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:18.005547+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:18.006659+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:22:22.789811+0000 | compress | METRIC - time 4.78s\n",
            "2025-04-20T00:22:22.791924+0000 | compress | METRIC - error 16.86\n",
            "2025-04-20T00:22:22.792691+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:22.793075+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(13/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.48it/s]\n",
            "(14/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:26.961326+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:27.792253+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:22:27.793242+0000 | compress | METRIC - error 20.92\n",
            "2025-04-20T00:22:27.794289+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:27.794913+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:22:27.796095+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:22:28.589293+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:22:28.590390+0000 | compress | METRIC - error 5.40\n",
            "2025-04-20T00:22:28.591070+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:28.591665+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:28.593103+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:22:29.390160+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:29.391138+0000 | compress | METRIC - error 1.96\n",
            "2025-04-20T00:22:29.392091+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:29.392756+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:29.393858+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:22:30.198093+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:30.199048+0000 | compress | METRIC - error 4.72\n",
            "2025-04-20T00:22:30.199729+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:30.200276+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:22:30.201727+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:22:31.032895+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:22:31.033902+0000 | compress | METRIC - error 61.66\n",
            "2025-04-20T00:22:31.034826+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:31.035382+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:31.036552+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:22:31.848830+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:22:31.849810+0000 | compress | METRIC - error 48.33\n",
            "2025-04-20T00:22:31.850793+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:31.851404+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:31.852383+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:22:36.700891+0000 | compress | METRIC - time 4.85s\n",
            "2025-04-20T00:22:36.703093+0000 | compress | METRIC - error 12.81\n",
            "2025-04-20T00:22:36.704051+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:36.704684+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(14/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.03it/s]\n",
            "(15/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:40.866622+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:41.672809+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:22:41.673936+0000 | compress | METRIC - error 60.05\n",
            "2025-04-20T00:22:41.674830+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:41.675542+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:22:41.676960+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:22:42.506804+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:22:42.507777+0000 | compress | METRIC - error 15.87\n",
            "2025-04-20T00:22:42.508675+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:42.509271+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:42.510457+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:22:43.330227+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:22:43.331222+0000 | compress | METRIC - error 3.34\n",
            "2025-04-20T00:22:43.332050+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:43.332487+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:43.333530+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:22:44.131409+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:44.132251+0000 | compress | METRIC - error 3.74\n",
            "2025-04-20T00:22:44.133134+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:44.133760+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:22:44.134952+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:22:44.986886+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:22:44.987878+0000 | compress | METRIC - error 73.80\n",
            "2025-04-20T00:22:44.988451+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:44.989020+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:44.990355+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:22:45.849749+0000 | compress | METRIC - time 0.86s\n",
            "2025-04-20T00:22:45.850776+0000 | compress | METRIC - error 55.71\n",
            "2025-04-20T00:22:45.851592+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:45.852121+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:45.853372+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:22:50.736429+0000 | compress | METRIC - time 4.88s\n",
            "2025-04-20T00:22:50.738223+0000 | compress | METRIC - error 20.64\n",
            "2025-04-20T00:22:50.739517+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:50.740130+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(15/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.96it/s]\n",
            "(16/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:54.902256+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:22:55.722596+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:22:55.723617+0000 | compress | METRIC - error 38.73\n",
            "2025-04-20T00:22:55.724677+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:55.725195+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:22:55.726279+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:22:56.515913+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:22:56.516970+0000 | compress | METRIC - error 7.54\n",
            "2025-04-20T00:22:56.517979+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:56.518487+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:56.519448+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:22:57.316109+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:57.317087+0000 | compress | METRIC - error 2.68\n",
            "2025-04-20T00:22:57.317801+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:57.318339+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:22:57.319332+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:22:58.118813+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:22:58.119927+0000 | compress | METRIC - error 12.31\n",
            "2025-04-20T00:22:58.120519+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:58.120909+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:22:58.122070+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:22:58.955675+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:22:58.956702+0000 | compress | METRIC - error 80.02\n",
            "2025-04-20T00:22:58.957739+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:58.958423+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:58.959705+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:22:59.780072+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:22:59.780993+0000 | compress | METRIC - error 50.70\n",
            "2025-04-20T00:22:59.781773+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:22:59.782589+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:22:59.783455+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:23:04.618555+0000 | compress | METRIC - time 4.83s\n",
            "2025-04-20T00:23:04.620193+0000 | compress | METRIC - error 14.06\n",
            "2025-04-20T00:23:04.621137+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:04.621877+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(16/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.40it/s]\n",
            "(17/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:08.794789+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:09.606256+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:23:09.607265+0000 | compress | METRIC - error 42.21\n",
            "2025-04-20T00:23:09.607971+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:09.608585+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:23:09.609554+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:23:10.398902+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:23:10.399989+0000 | compress | METRIC - error 11.78\n",
            "2025-04-20T00:23:10.400936+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:10.401433+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:10.402512+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:23:11.203790+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:23:11.204736+0000 | compress | METRIC - error 3.29\n",
            "2025-04-20T00:23:11.205371+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:11.205892+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:11.207169+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:23:12.024884+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:12.025892+0000 | compress | METRIC - error 4.18\n",
            "2025-04-20T00:23:12.026781+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:12.027431+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:23:12.028502+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:23:12.877283+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:23:12.878271+0000 | compress | METRIC - error 96.48\n",
            "2025-04-20T00:23:12.878996+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:12.879515+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:12.880511+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:23:13.725183+0000 | compress | METRIC - time 0.84s\n",
            "2025-04-20T00:23:13.726296+0000 | compress | METRIC - error 56.67\n",
            "2025-04-20T00:23:13.726941+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:13.727428+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:13.728556+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:23:18.528938+0000 | compress | METRIC - time 4.80s\n",
            "2025-04-20T00:23:18.531059+0000 | compress | METRIC - error 18.90\n",
            "2025-04-20T00:23:18.531636+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:18.532013+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(17/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.60it/s]\n",
            "(18/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:22.681506+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:23.514825+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:23:23.515607+0000 | compress | METRIC - error 38.29\n",
            "2025-04-20T00:23:23.516399+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:23.516881+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:23:23.518038+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:23:24.336672+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:24.337796+0000 | compress | METRIC - error 9.15\n",
            "2025-04-20T00:23:24.338835+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:24.339363+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:24.340760+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:23:25.149523+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:23:25.150509+0000 | compress | METRIC - error 2.78\n",
            "2025-04-20T00:23:25.151210+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:25.151682+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:25.152686+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:23:25.948421+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:23:25.949433+0000 | compress | METRIC - error 3.96\n",
            "2025-04-20T00:23:25.950305+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:25.950889+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:23:25.951932+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:23:26.798939+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:23:26.800025+0000 | compress | METRIC - error 117.75\n",
            "2025-04-20T00:23:26.800767+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:26.801250+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:26.802281+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:23:27.624378+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:27.625311+0000 | compress | METRIC - error 59.51\n",
            "2025-04-20T00:23:27.626156+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:27.626690+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:27.627749+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:23:32.414997+0000 | compress | METRIC - time 4.79s\n",
            "2025-04-20T00:23:32.417070+0000 | compress | METRIC - error 23.25\n",
            "2025-04-20T00:23:32.417834+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:32.418381+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(18/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.22it/s]\n",
            "(19/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:36.579858+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:37.396540+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:37.397271+0000 | compress | METRIC - error 30.57\n",
            "2025-04-20T00:23:37.398214+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:37.398837+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:23:37.400112+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:23:38.183162+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:23:38.184261+0000 | compress | METRIC - error 9.36\n",
            "2025-04-20T00:23:38.184913+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:38.185424+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:38.186421+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:23:38.981675+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:23:38.982636+0000 | compress | METRIC - error 3.56\n",
            "2025-04-20T00:23:38.983584+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:38.984280+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:38.985609+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:23:39.804387+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:39.805357+0000 | compress | METRIC - error 3.92\n",
            "2025-04-20T00:23:39.806326+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:39.806956+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:23:39.808079+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:23:40.626007+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:40.626996+0000 | compress | METRIC - error 136.49\n",
            "2025-04-20T00:23:40.627852+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:40.628501+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:40.629604+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:23:41.450054+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:23:41.451009+0000 | compress | METRIC - error 71.34\n",
            "2025-04-20T00:23:41.451730+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:41.452232+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:41.453431+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:23:46.257150+0000 | compress | METRIC - time 4.80s\n",
            "2025-04-20T00:23:46.259476+0000 | compress | METRIC - error 30.30\n",
            "2025-04-20T00:23:46.260237+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:46.260731+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(19/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.75it/s]\n",
            "(20/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:50.428744+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:23:51.236779+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:23:51.237768+0000 | compress | METRIC - error 36.48\n",
            "2025-04-20T00:23:51.238351+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:51.239000+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:23:51.240353+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:23:52.029801+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:23:52.030830+0000 | compress | METRIC - error 11.92\n",
            "2025-04-20T00:23:52.031528+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:52.032030+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:52.032892+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:23:52.815259+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:23:52.816201+0000 | compress | METRIC - error 5.61\n",
            "2025-04-20T00:23:52.816942+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:52.817459+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:23:52.818578+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:23:53.609984+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:23:53.610944+0000 | compress | METRIC - error 8.53\n",
            "2025-04-20T00:23:53.611735+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:53.612235+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:23:53.613188+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:23:54.428335+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:23:54.429296+0000 | compress | METRIC - error 190.86\n",
            "2025-04-20T00:23:54.430024+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:54.430507+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:54.431475+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:23:55.243518+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:23:55.244445+0000 | compress | METRIC - error 90.57\n",
            "2025-04-20T00:23:55.245194+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:23:55.245646+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:23:55.246630+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:24:00.097505+0000 | compress | METRIC - time 4.85s\n",
            "2025-04-20T00:24:00.098384+0000 | compress | METRIC - error 57.87\n",
            "2025-04-20T00:24:00.099283+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:00.099831+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(20/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.66it/s]\n",
            "(21/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:04.263823+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:05.074875+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:24:05.075688+0000 | compress | METRIC - error 40.33\n",
            "2025-04-20T00:24:05.076375+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:05.076950+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:24:05.077910+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:24:05.861846+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:24:05.862612+0000 | compress | METRIC - error 15.42\n",
            "2025-04-20T00:24:05.863304+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:05.863900+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:05.864878+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:24:06.663976+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:24:06.665011+0000 | compress | METRIC - error 8.04\n",
            "2025-04-20T00:24:06.665870+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:06.666603+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:06.667845+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:24:07.511740+0000 | compress | METRIC - time 0.84s\n",
            "2025-04-20T00:24:07.512707+0000 | compress | METRIC - error 12.39\n",
            "2025-04-20T00:24:07.513553+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:07.514037+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:24:07.515052+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:24:08.326063+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:24:08.327083+0000 | compress | METRIC - error 215.72\n",
            "2025-04-20T00:24:08.328138+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:08.328797+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:08.329858+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:24:09.146279+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:24:09.147283+0000 | compress | METRIC - error 92.40\n",
            "2025-04-20T00:24:09.148299+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:09.148958+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:09.150225+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:24:13.946902+0000 | compress | METRIC - time 4.80s\n",
            "2025-04-20T00:24:13.949022+0000 | compress | METRIC - error 48.95\n",
            "2025-04-20T00:24:13.949645+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:13.950099+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(21/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.01it/s]\n",
            "(22/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:18.105474+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:18.917020+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:24:18.917794+0000 | compress | METRIC - error 44.80\n",
            "2025-04-20T00:24:18.918638+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:18.919114+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:24:18.920000+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:24:19.708349+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:24:19.709311+0000 | compress | METRIC - error 10.57\n",
            "2025-04-20T00:24:19.710135+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:19.710788+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:19.711783+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:24:20.506028+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:24:20.507102+0000 | compress | METRIC - error 7.00\n",
            "2025-04-20T00:24:20.508085+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:20.508617+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:20.509709+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:24:21.302948+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:24:21.303972+0000 | compress | METRIC - error 8.17\n",
            "2025-04-20T00:24:21.304939+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:21.305454+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:24:21.306556+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:24:22.139457+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:24:22.140496+0000 | compress | METRIC - error 344.82\n",
            "2025-04-20T00:24:22.141461+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:22.141982+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:22.143131+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:24:22.980000+0000 | compress | METRIC - time 0.84s\n",
            "2025-04-20T00:24:22.981013+0000 | compress | METRIC - error 134.06\n",
            "2025-04-20T00:24:22.981734+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:22.982458+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:22.983554+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:24:27.822376+0000 | compress | METRIC - time 4.84s\n",
            "2025-04-20T00:24:27.824475+0000 | compress | METRIC - error 83.18\n",
            "2025-04-20T00:24:27.825343+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:27.826051+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(22/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.79it/s]\n",
            "(23/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:31.991094+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:32.796856+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:24:32.797862+0000 | compress | METRIC - error 34.35\n",
            "2025-04-20T00:24:32.798729+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:32.799472+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:24:32.800403+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:24:33.592238+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:24:33.593233+0000 | compress | METRIC - error 9.97\n",
            "2025-04-20T00:24:33.593974+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:33.594462+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:33.595408+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:24:34.420537+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:24:34.421545+0000 | compress | METRIC - error 12.60\n",
            "2025-04-20T00:24:34.422313+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:34.422866+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:34.423991+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:24:35.234652+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:24:35.235699+0000 | compress | METRIC - error 15.18\n",
            "2025-04-20T00:24:35.236719+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:35.237300+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:24:35.238765+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:24:36.066719+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:24:36.067482+0000 | compress | METRIC - error 454.97\n",
            "2025-04-20T00:24:36.068252+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:36.068759+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:36.069802+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:24:36.933955+0000 | compress | METRIC - time 0.86s\n",
            "2025-04-20T00:24:36.934910+0000 | compress | METRIC - error 164.01\n",
            "2025-04-20T00:24:36.935716+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:36.936422+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:36.937514+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:24:41.728224+0000 | compress | METRIC - time 4.79s\n",
            "2025-04-20T00:24:41.730314+0000 | compress | METRIC - error 107.78\n",
            "2025-04-20T00:24:41.731060+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:41.731621+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(23/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.32it/s]\n",
            "(24/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:45.883709+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:46.687080+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:24:46.687853+0000 | compress | METRIC - error 43.70\n",
            "2025-04-20T00:24:46.688525+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:46.689233+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:24:46.690353+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:24:47.481291+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:24:47.482281+0000 | compress | METRIC - error 14.84\n",
            "2025-04-20T00:24:47.483023+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:47.483637+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:47.484708+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:24:48.295731+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:24:48.296762+0000 | compress | METRIC - error 18.45\n",
            "2025-04-20T00:24:48.297597+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:48.298182+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:24:48.299415+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:24:49.098404+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:24:49.099380+0000 | compress | METRIC - error 11.62\n",
            "2025-04-20T00:24:49.100235+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:49.100942+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:24:49.102089+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:24:49.925986+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:24:49.926994+0000 | compress | METRIC - error 513.65\n",
            "2025-04-20T00:24:49.927743+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:49.928262+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:49.929356+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:24:50.750556+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:24:50.751608+0000 | compress | METRIC - error 173.00\n",
            "2025-04-20T00:24:50.752415+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:50.752988+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:24:50.754171+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:24:55.628734+0000 | compress | METRIC - time 4.87s\n",
            "2025-04-20T00:24:55.629475+0000 | compress | METRIC - error 124.02\n",
            "2025-04-20T00:24:55.630231+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:24:55.630856+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(24/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 89.66it/s]\n",
            "(25/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:24:59.779591+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:00.587515+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:25:00.588289+0000 | compress | METRIC - error 39.08\n",
            "2025-04-20T00:25:00.589023+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:00.589837+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:25:00.591017+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:25:01.389084+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:25:01.390158+0000 | compress | METRIC - error 10.11\n",
            "2025-04-20T00:25:01.391014+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:01.391557+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:01.392534+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:25:02.204664+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:25:02.205613+0000 | compress | METRIC - error 27.76\n",
            "2025-04-20T00:25:02.206365+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:02.206889+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:02.207910+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:25:03.001182+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:25:03.002160+0000 | compress | METRIC - error 14.64\n",
            "2025-04-20T00:25:03.002986+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:03.003618+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:25:03.004765+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:25:03.818895+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:25:03.819905+0000 | compress | METRIC - error 478.15\n",
            "2025-04-20T00:25:03.820834+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:03.821387+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:03.822465+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:25:04.655512+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:25:04.656500+0000 | compress | METRIC - error 175.56\n",
            "2025-04-20T00:25:04.657211+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:04.657664+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:04.658602+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:25:09.430627+0000 | compress | METRIC - time 4.77s\n",
            "2025-04-20T00:25:09.431793+0000 | compress | METRIC - error 130.18\n",
            "2025-04-20T00:25:09.432487+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:09.433230+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(25/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.65it/s]\n",
            "(26/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:13.601431+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:14.429430+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:25:14.430373+0000 | compress | METRIC - error 23.90\n",
            "2025-04-20T00:25:14.430958+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:14.431357+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:25:14.432659+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:25:15.230730+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:25:15.231756+0000 | compress | METRIC - error 7.06\n",
            "2025-04-20T00:25:15.232460+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:15.232998+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:15.234023+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:25:16.016671+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:25:16.017634+0000 | compress | METRIC - error 46.96\n",
            "2025-04-20T00:25:16.018318+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:16.018793+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:16.019663+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:25:16.815204+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:25:16.816194+0000 | compress | METRIC - error 9.25\n",
            "2025-04-20T00:25:16.816928+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:16.817476+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:25:16.818515+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:25:17.641759+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:25:17.642754+0000 | compress | METRIC - error 398.66\n",
            "2025-04-20T00:25:17.643787+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:17.644433+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:17.645664+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:25:18.485798+0000 | compress | METRIC - time 0.84s\n",
            "2025-04-20T00:25:18.486813+0000 | compress | METRIC - error 192.24\n",
            "2025-04-20T00:25:18.487725+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:18.488231+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:18.489369+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:25:23.293201+0000 | compress | METRIC - time 4.80s\n",
            "2025-04-20T00:25:23.295491+0000 | compress | METRIC - error 237.76\n",
            "2025-04-20T00:25:23.296252+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:23.297046+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(26/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.69it/s]\n",
            "(27/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 46.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:27.474904+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:28.297973+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:25:28.298754+0000 | compress | METRIC - error 43.80\n",
            "2025-04-20T00:25:28.299424+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:28.299888+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:25:28.301003+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:25:29.090541+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:25:29.091626+0000 | compress | METRIC - error 11.39\n",
            "2025-04-20T00:25:29.092664+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:29.093169+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:29.094350+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:25:29.919065+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:25:29.920044+0000 | compress | METRIC - error 61.09\n",
            "2025-04-20T00:25:29.920780+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:29.921209+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:29.922196+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:25:30.736397+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:25:30.737116+0000 | compress | METRIC - error 6.23\n",
            "2025-04-20T00:25:30.737859+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:30.738347+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:25:30.739164+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:25:31.552140+0000 | compress | METRIC - time 0.81s\n",
            "2025-04-20T00:25:31.553107+0000 | compress | METRIC - error 434.82\n",
            "2025-04-20T00:25:31.553741+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:31.554395+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:31.555081+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:25:32.376865+0000 | compress | METRIC - time 0.82s\n",
            "2025-04-20T00:25:32.377899+0000 | compress | METRIC - error 229.13\n",
            "2025-04-20T00:25:32.378642+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:32.379193+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:32.380131+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:25:37.231881+0000 | compress | METRIC - time 4.85s\n",
            "2025-04-20T00:25:37.233996+0000 | compress | METRIC - error 3057.83\n",
            "2025-04-20T00:25:37.234603+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:37.235431+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(27/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 88.72it/s]\n",
            "(28/29): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:41.401784+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:42.232019+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:25:42.232815+0000 | compress | METRIC - error 44.26\n",
            "2025-04-20T00:25:42.233540+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:42.234214+0000 | compress | METRIC - Compressed module size: 9.451008 MB\n",
            "2025-04-20T00:25:42.235275+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.k_proj using 128 samples\n",
            "2025-04-20T00:25:43.019390+0000 | compress | METRIC - time 0.78s\n",
            "2025-04-20T00:25:43.020595+0000 | compress | METRIC - error 10.70\n",
            "2025-04-20T00:25:43.021359+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:43.021874+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:43.022978+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.v_proj using 128 samples\n",
            "2025-04-20T00:25:43.815981+0000 | compress | METRIC - time 0.79s\n",
            "2025-04-20T00:25:43.816991+0000 | compress | METRIC - error 67.50\n",
            "2025-04-20T00:25:43.817749+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:43.818269+0000 | compress | METRIC - Compressed module size: 1.575168 MB\n",
            "2025-04-20T00:25:43.819333+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.o_proj using 128 samples\n",
            "2025-04-20T00:25:44.620679+0000 | compress | METRIC - time 0.80s\n",
            "2025-04-20T00:25:44.621640+0000 | compress | METRIC - error 65.47\n",
            "2025-04-20T00:25:44.622382+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:44.623070+0000 | compress | METRIC - Compressed module size: 9.444864 MB\n",
            "2025-04-20T00:25:44.624161+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.gate_proj using 128 samples\n",
            "2025-04-20T00:25:45.450857+0000 | compress | METRIC - time 0.83s\n",
            "2025-04-20T00:25:45.451907+0000 | compress | METRIC - error 741.19\n",
            "2025-04-20T00:25:45.452884+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:45.453398+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:45.454671+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.up_proj using 128 samples\n",
            "2025-04-20T00:25:46.304426+0000 | compress | METRIC - time 0.85s\n",
            "2025-04-20T00:25:46.305453+0000 | compress | METRIC - error 488.80\n",
            "2025-04-20T00:25:46.306443+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:46.306946+0000 | compress | METRIC - Compressed module size: 55.09504 MB\n",
            "2025-04-20T00:25:46.307993+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.down_proj using 128 samples\n",
            "2025-04-20T00:25:51.164289+0000 | compress | METRIC - time 4.86s\n",
            "2025-04-20T00:25:51.166395+0000 | compress | METRIC - error 1501.93\n",
            "2025-04-20T00:25:51.167210+0000 | compress | METRIC - GPU 0 | usage: 23.49% | total memory: 42 GB\n",
            "2025-04-20T00:25:51.167781+0000 | compress | METRIC - Compressed module size: 55.05792 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(28/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 87.87it/s]\n",
            "(29/29): Calibrating: 100%|██████████| 128/128 [00:03<00:00, 37.87it/s]\n",
            "(29/29): Propagating: 100%|██████████| 128/128 [00:03<00:00, 37.67it/s]\n",
            "manager stage: Modifiers initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:59.414289+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "manager stage: Modifiers finalized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:25:59.417260+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
            "2025-04-20T00:25:59.417700+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking whether model follows 2:4 sparsity structure: 100%|██████████| 197/197 [00:02<00:00, 75.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20T00:26:41.856897+0000 | get_model_compressor | INFO - Inferring a sparsity configuration requires a global sparsity calculation. This can be costly for large models. To skip the calculation of compression statistics set skip_compression_stats=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating model sparsity: 100%|██████████| 731/731 [00:02<00:00, 287.08it/s]\n",
            "Calculating quantization compression ratio: 284it [00:00, 459.86it/s]\n",
            "Quantized Compression: 100%|██████████| 731/731 [00:02<00:00, 246.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to: /content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/wandb/ /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "id": "5S5GBtuhcNsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/tensorboard/ /content/drive/MyDrive/CS594/"
      ],
      "metadata": {
        "id": "xKC-SzbWcPZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm_eval==v0.4.3\n",
        "!pip install transformers vllm torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cjbpPwrjcZDR",
        "outputId": "60bd1822-e868-4dc3-de12-3d19b22b08b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lm_eval==v0.4.3\n",
            "  Downloading lm_eval-0.4.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (1.5.2)\n",
            "Collecting evaluate (from lm_eval==v0.4.3)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (3.5.0)\n",
            "Collecting jsonlines (from lm_eval==v0.4.3)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==v0.4.3)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==v0.4.3)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==v0.4.3)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==v0.4.3)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (1.6.1)\n",
            "Collecting sqlitedict (from lm_eval==v0.4.3)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (2.6.0+cu124)\n",
            "Collecting tqdm-multiprocess (from lm_eval==v0.4.3)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (4.49.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (0.3.8)\n",
            "Collecting word2number (from lm_eval==v0.4.3)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from lm_eval==v0.4.3) (10.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==v0.4.3) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm_eval==v0.4.3) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval==v0.4.3) (3.11.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==v0.4.3) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==v0.4.3)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==v0.4.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==v0.4.3) (5.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==v0.4.3) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==v0.4.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm_eval==v0.4.3) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm_eval==v0.4.3) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm_eval==v0.4.3) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==v0.4.3) (75.2.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==v0.4.3) (1.19.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==v0.4.3) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==v0.4.3) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==v0.4.3) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm_eval==v0.4.3) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==v0.4.3) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm_eval==v0.4.3) (2025.2)\n",
            "Downloading lm_eval-0.4.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=96ac26812826b2eea451557555edc579ad56debd694fd5611ec8267b5b8f6545\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=d76c2ccd0f6dda36293d47acb30e20086ecce4de398db6c6af895ab8e52ca47d\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=59db187cbd70b9923fc01ae6e53c6b61e7f0e28fbd29a60b6fa06b096d7e25e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, tcolorpy, pybind11, portalocker, pathvalidate, mbstrdecoder, jsonlines, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, DataProperty, tabledata, evaluate, pytablewriter, lm_eval\n",
            "Successfully installed DataProperty-1.1.0 colorama-0.4.6 evaluate-0.4.3 jsonlines-4.0.0 lm_eval-0.4.3 mbstrdecoder-1.1.4 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Collecting vllm\n",
            "  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (5.29.4)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.75.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.1.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.9 (from vllm)\n",
            "  Downloading llguidance-0.7.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.18 (from vllm)\n",
            "  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.16.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.3)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.14.1)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
            "  Downloading ray-2.43.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Collecting xformers==0.0.29.post2 (from vllm)\n",
            "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
            "  Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Collecting importlib_metadata (from vllm)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.5.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.19.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.2)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.14.1-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl (294.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.1/294.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.16.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions_ai-0.4.3-py3-none-any.whl (5.4 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.43.0-cp311-cp311-manylinux2014_x86_64.whl (67.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.1-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blake3, uvloop, uvicorn, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, ninja, msgspec, llvmlite, llguidance, lark, interegular, importlib_metadata, httptools, hf-xet, gguf, dnspython, diskcache, astor, airportsdata, watchfiles, tiktoken, starlette, opentelemetry-proto, opentelemetry-api, numba, email-validator, depyf, rich-toolkit, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, lm-format-enforcer, fastapi, xformers, transformers, ray, outlines_core, opentelemetry-sdk, mistral_common, fastapi-cli, xgrammar, outlines, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, vllm\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.32.1\n",
            "    Uninstalling opentelemetry-api-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.32.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.53b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.53b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.53b1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.49.0\n",
            "    Uninstalling transformers-4.49.0:\n",
            "      Successfully uninstalled transformers-4.49.0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.32.1\n",
            "    Uninstalling opentelemetry-sdk-1.32.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmcompressor 0.5.0 requires transformers<4.50,>4.0, but you have transformers 4.51.3 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-api>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-api 1.26.0 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires opentelemetry-sdk>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-sdk 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250224 astor-0.8.1 blake3-1.0.4 depyf-0.18.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.12 fastapi-cli-0.0.7 gguf-0.16.2 hf-xet-1.0.3 httptools-0.6.4 importlib_metadata-8.0.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.16 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.5.4 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.3 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.6 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 ray-2.43.0 rich-toolkit-0.14.1 starlette-0.46.2 tiktoken-0.9.0 transformers-4.51.3 uvicorn-0.34.2 uvloop-0.21.0 vllm-0.8.4 watchfiles-1.0.5 xformers-0.0.29.post2 xgrammar-0.1.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata",
                  "transformers"
                ]
              },
              "id": "4ab28b5d8a8d4789adf5fb621ea0ac12"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "  --model hf \\\n",
        "  --model_args pretrained=\"/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8\",device_map=\"auto\" \\\n",
        "  --tasks mmlu_high_school_computer_science,gsm8k \\\n",
        "  --num_fewshot 5 \\\n",
        "  --batch_size 1 \\\n",
        "  --max_batch_size 1 \\\n",
        "  --limit 250\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6RAGdSrn-cK",
        "outputId": "90e948ba-a661-4d1a-9de8-778ba52d567a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20 00:38:14.814941: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-20 00:38:14.832471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745109494.854273    7195 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745109494.860666    7195 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-20 00:38:14.882059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 04-20 00:38:18 [__init__.py:239] Automatically detected platform cuda.\n",
            "2025-04-20:00:38:20,895 INFO     [__main__.py:272] Verbosity set to INFO\n",
            "2025-04-20:00:38:25,821 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
            "2025-04-20:00:38:25,823 INFO     [__main__.py:369] Selected Tasks: ['gsm8k', 'mmlu_high_school_computer_science']\n",
            "2025-04-20:00:38:25,826 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2025-04-20:00:38:25,826 INFO     [evaluator.py:189] Initializing hf model, with arguments: {'pretrained': '/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8', 'device_map': 'auto'}\n",
            "2025-04-20:00:38:25,861 INFO     [huggingface.py:170] Using device 'cuda'\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "2025-04-20:00:38:26,639 INFO     [modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "README.md: 100% 7.94k/7.94k [00:00<00:00, 38.4MB/s]\n",
            "train-00000-of-00001.parquet: 100% 2.31M/2.31M [00:00<00:00, 28.0MB/s]\n",
            "test-00000-of-00001.parquet: 100% 419k/419k [00:00<00:00, 258MB/s]\n",
            "Generating train split: 100% 7473/7473 [00:00<00:00, 216823.70 examples/s]\n",
            "Generating test split: 100% 1319/1319 [00:00<00:00, 331751.44 examples/s]\n",
            "README.md: 100% 1.11k/1.11k [00:00<00:00, 10.1MB/s]\n",
            "mmlu_no_train.py: 100% 5.86k/5.86k [00:00<00:00, 32.7MB/s]\n",
            "data.tar: 100% 166M/166M [00:00<00:00, 263MB/s]\n",
            "Generating test split: 100 examples [00:00, 1338.16 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3398.64 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.40 examples/s]\n",
            "2025-04-20:00:38:33,081 WARNING  [evaluator.py:251] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
            "2025-04-20:00:38:33,081 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
            "2025-04-20:00:38:33,081 WARNING  [evaluator.py:251] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
            "2025-04-20:00:38:33,081 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
            "2025-04-20:00:38:33,082 INFO     [task.py:411] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 140.32it/s]\n",
            "2025-04-20:00:38:33,800 INFO     [task.py:411] Building contexts for gsm8k on rank 0...\n",
            "100% 250/250 [00:01<00:00, 242.34it/s]\n",
            "2025-04-20:00:38:34,838 INFO     [evaluator.py:438] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 400/400 [00:38<00:00, 10.37it/s]\n",
            "2025-04-20:00:39:15,356 INFO     [evaluator.py:438] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Running generate_until requests: 100% 250/250 [1:50:57<00:00, 26.63s/it]\n",
            "2025-04-20:02:30:12,981 WARNING  [huggingface.py:1315] Failed to get model SHA for /content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-04-20:02:30:15,513 INFO     [evaluation_tracker.py:240] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/drive/MyDrive/CS594/DeepSeek-R1-Distill-Qwen-1.5B-gptqquantized.w8a8,device_map=auto), gen_kwargs: (None), limit: 250.0, num_fewshot: 5, batch_size: 1\n",
            "|           Tasks            |Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
            "|----------------------------|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
            "|gsm8k                       |      3|flexible-extract|     5|exact_match|↑  |0.708|±  |0.0288|\n",
            "|                            |       |strict-match    |     5|exact_match|↑  |0.700|±  |0.0290|\n",
            "|high_school_computer_science|      0|none            |     5|acc        |↑  |0.480|±  |0.0502|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}